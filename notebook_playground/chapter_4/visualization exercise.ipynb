{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# generate a toy dataset of only two features and three label classes\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# one-hot encode output variable\n",
    "y = to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (800, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into 80% training data and 20% test data \n",
    "# note that we did not create a validation dataset in this example for simplicity\n",
    "n_train = 200\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                75        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# develop the baseline model architecture\n",
    "# here we are building a very simple, two-layer network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 800 samples\n",
      "Epoch 1/1000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.6004 - acc: 0.3100 - val_loss: 1.5308 - val_acc: 0.3412\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 1.4963 - acc: 0.3100 - val_loss: 1.4268 - val_acc: 0.3438\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 0s 168us/step - loss: 1.3988 - acc: 0.3250 - val_loss: 1.3348 - val_acc: 0.3463\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 1.3166 - acc: 0.3350 - val_loss: 1.2517 - val_acc: 0.3700\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 1.2393 - acc: 0.3600 - val_loss: 1.1803 - val_acc: 0.3850\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2964 - acc: 0.406 - 0s 145us/step - loss: 1.1786 - acc: 0.3950 - val_loss: 1.1183 - val_acc: 0.4012\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 1.1232 - acc: 0.4200 - val_loss: 1.0670 - val_acc: 0.4088\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 0s 155us/step - loss: 1.0772 - acc: 0.4200 - val_loss: 1.0244 - val_acc: 0.4275\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 0s 188us/step - loss: 1.0412 - acc: 0.4250 - val_loss: 0.9851 - val_acc: 0.4412\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 1.0076 - acc: 0.4500 - val_loss: 0.9487 - val_acc: 0.4700\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 0s 170us/step - loss: 0.9765 - acc: 0.4900 - val_loss: 0.9170 - val_acc: 0.5012\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.9487 - acc: 0.5000 - val_loss: 0.8885 - val_acc: 0.5475\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.9237 - acc: 0.5150 - val_loss: 0.8615 - val_acc: 0.5775\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.9005 - acc: 0.5300 - val_loss: 0.8366 - val_acc: 0.6038\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.8779 - acc: 0.5450 - val_loss: 0.8131 - val_acc: 0.6088\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.8566 - acc: 0.5650 - val_loss: 0.7910 - val_acc: 0.6175\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.8354 - acc: 0.5700 - val_loss: 0.7700 - val_acc: 0.6350\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.8161 - acc: 0.5900 - val_loss: 0.7505 - val_acc: 0.6462\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 0s 165us/step - loss: 0.7971 - acc: 0.5950 - val_loss: 0.7335 - val_acc: 0.6575\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.7806 - acc: 0.6100 - val_loss: 0.7184 - val_acc: 0.6687\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.7654 - acc: 0.6250 - val_loss: 0.7056 - val_acc: 0.6775\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 0s 173us/step - loss: 0.7523 - acc: 0.6400 - val_loss: 0.6940 - val_acc: 0.6887\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 0s 174us/step - loss: 0.7400 - acc: 0.6350 - val_loss: 0.6844 - val_acc: 0.6987\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 0s 185us/step - loss: 0.7287 - acc: 0.6550 - val_loss: 0.6767 - val_acc: 0.7150\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 0s 231us/step - loss: 0.7187 - acc: 0.6750 - val_loss: 0.6696 - val_acc: 0.7200\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.7100 - acc: 0.6800 - val_loss: 0.6621 - val_acc: 0.7238\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 0s 178us/step - loss: 0.7023 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.7275\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 0s 171us/step - loss: 0.6941 - acc: 0.6950 - val_loss: 0.6513 - val_acc: 0.7312\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 0s 175us/step - loss: 0.6871 - acc: 0.6950 - val_loss: 0.6463 - val_acc: 0.7338\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 0s 194us/step - loss: 0.6800 - acc: 0.7000 - val_loss: 0.6422 - val_acc: 0.7375\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 0s 165us/step - loss: 0.6735 - acc: 0.7000 - val_loss: 0.6386 - val_acc: 0.7312\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 0s 170us/step - loss: 0.6679 - acc: 0.7050 - val_loss: 0.6350 - val_acc: 0.7362\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 0s 169us/step - loss: 0.6617 - acc: 0.7100 - val_loss: 0.6308 - val_acc: 0.7375\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 0s 224us/step - loss: 0.6562 - acc: 0.7150 - val_loss: 0.6276 - val_acc: 0.7338\n",
      "Epoch 35/1000\n",
      "200/200 [==============================] - 0s 169us/step - loss: 0.6515 - acc: 0.7150 - val_loss: 0.6241 - val_acc: 0.7350\n",
      "Epoch 36/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.6463 - acc: 0.7200 - val_loss: 0.6210 - val_acc: 0.7362\n",
      "Epoch 37/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.6419 - acc: 0.7250 - val_loss: 0.6194 - val_acc: 0.7412\n",
      "Epoch 38/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.6378 - acc: 0.7300 - val_loss: 0.6170 - val_acc: 0.7450\n",
      "Epoch 39/1000\n",
      "200/200 [==============================] - 0s 170us/step - loss: 0.6341 - acc: 0.7300 - val_loss: 0.6137 - val_acc: 0.7500\n",
      "Epoch 40/1000\n",
      "200/200 [==============================] - 0s 190us/step - loss: 0.6301 - acc: 0.7300 - val_loss: 0.6130 - val_acc: 0.7538\n",
      "Epoch 41/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.6266 - acc: 0.7250 - val_loss: 0.6109 - val_acc: 0.7500\n",
      "Epoch 42/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.6231 - acc: 0.7250 - val_loss: 0.6075 - val_acc: 0.7475\n",
      "Epoch 43/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.6192 - acc: 0.7250 - val_loss: 0.6046 - val_acc: 0.7512\n",
      "Epoch 44/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.6160 - acc: 0.7250 - val_loss: 0.6013 - val_acc: 0.7512\n",
      "Epoch 45/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.6127 - acc: 0.7300 - val_loss: 0.5988 - val_acc: 0.7500\n",
      "Epoch 46/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.6094 - acc: 0.7350 - val_loss: 0.5968 - val_acc: 0.7500\n",
      "Epoch 47/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.6063 - acc: 0.7350 - val_loss: 0.5948 - val_acc: 0.7525\n",
      "Epoch 48/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.6031 - acc: 0.7350 - val_loss: 0.5919 - val_acc: 0.7550\n",
      "Epoch 49/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6004 - acc: 0.7300 - val_loss: 0.5888 - val_acc: 0.7562\n",
      "Epoch 50/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.5970 - acc: 0.7300 - val_loss: 0.5861 - val_acc: 0.7550\n",
      "Epoch 51/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.5943 - acc: 0.7400 - val_loss: 0.5836 - val_acc: 0.7525\n",
      "Epoch 52/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.5916 - acc: 0.7500 - val_loss: 0.5824 - val_acc: 0.7600\n",
      "Epoch 53/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.5890 - acc: 0.7500 - val_loss: 0.5789 - val_acc: 0.7550\n",
      "Epoch 54/1000\n",
      "200/200 [==============================] - 0s 191us/step - loss: 0.5860 - acc: 0.7500 - val_loss: 0.5785 - val_acc: 0.7675\n",
      "Epoch 55/1000\n",
      "200/200 [==============================] - 0s 196us/step - loss: 0.5832 - acc: 0.7400 - val_loss: 0.5788 - val_acc: 0.7762\n",
      "Epoch 56/1000\n",
      "200/200 [==============================] - 0s 184us/step - loss: 0.5807 - acc: 0.7450 - val_loss: 0.5774 - val_acc: 0.7762\n",
      "Epoch 57/1000\n",
      "200/200 [==============================] - 0s 207us/step - loss: 0.5779 - acc: 0.7450 - val_loss: 0.5760 - val_acc: 0.7800\n",
      "Epoch 58/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.5755 - acc: 0.7450 - val_loss: 0.5720 - val_acc: 0.7775\n",
      "Epoch 59/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.5731 - acc: 0.7450 - val_loss: 0.5680 - val_acc: 0.7800\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 157us/step - loss: 0.5718 - acc: 0.7600 - val_loss: 0.5643 - val_acc: 0.7688\n",
      "Epoch 61/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.5693 - acc: 0.7550 - val_loss: 0.5618 - val_acc: 0.7800\n",
      "Epoch 62/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.5668 - acc: 0.7550 - val_loss: 0.5622 - val_acc: 0.7788\n",
      "Epoch 63/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.5643 - acc: 0.7500 - val_loss: 0.5624 - val_acc: 0.7788\n",
      "Epoch 64/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.5620 - acc: 0.7600 - val_loss: 0.5617 - val_acc: 0.7775\n",
      "Epoch 65/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.5597 - acc: 0.7600 - val_loss: 0.5595 - val_acc: 0.7800\n",
      "Epoch 66/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.5575 - acc: 0.7550 - val_loss: 0.5568 - val_acc: 0.7800\n",
      "Epoch 67/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.5553 - acc: 0.7550 - val_loss: 0.5553 - val_acc: 0.7863\n",
      "Epoch 68/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.5535 - acc: 0.7550 - val_loss: 0.5514 - val_acc: 0.7837\n",
      "Epoch 69/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.5510 - acc: 0.7650 - val_loss: 0.5511 - val_acc: 0.7900\n",
      "Epoch 70/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.5490 - acc: 0.7650 - val_loss: 0.5505 - val_acc: 0.7875\n",
      "Epoch 71/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.5468 - acc: 0.7650 - val_loss: 0.5493 - val_acc: 0.7875\n",
      "Epoch 72/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.5455 - acc: 0.7750 - val_loss: 0.5448 - val_acc: 0.7850\n",
      "Epoch 73/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.5430 - acc: 0.7700 - val_loss: 0.5441 - val_acc: 0.7850\n",
      "Epoch 74/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.5410 - acc: 0.7700 - val_loss: 0.5418 - val_acc: 0.7900\n",
      "Epoch 75/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.5388 - acc: 0.7700 - val_loss: 0.5437 - val_acc: 0.7887\n",
      "Epoch 76/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.5369 - acc: 0.7600 - val_loss: 0.5456 - val_acc: 0.7887\n",
      "Epoch 77/1000\n",
      "200/200 [==============================] - 0s 159us/step - loss: 0.5357 - acc: 0.7600 - val_loss: 0.5434 - val_acc: 0.7900\n",
      "Epoch 78/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4873 - acc: 0.812 - 0s 161us/step - loss: 0.5337 - acc: 0.7600 - val_loss: 0.5405 - val_acc: 0.7913\n",
      "Epoch 79/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.5313 - acc: 0.7650 - val_loss: 0.5322 - val_acc: 0.7963\n",
      "Epoch 80/1000\n",
      "200/200 [==============================] - 0s 164us/step - loss: 0.5290 - acc: 0.7600 - val_loss: 0.5287 - val_acc: 0.7987\n",
      "Epoch 81/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.5276 - acc: 0.7650 - val_loss: 0.5251 - val_acc: 0.8025\n",
      "Epoch 82/1000\n",
      "200/200 [==============================] - 0s 190us/step - loss: 0.5263 - acc: 0.7600 - val_loss: 0.5232 - val_acc: 0.8025\n",
      "Epoch 83/1000\n",
      "200/200 [==============================] - 0s 177us/step - loss: 0.5247 - acc: 0.7600 - val_loss: 0.5211 - val_acc: 0.8050\n",
      "Epoch 84/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.5228 - acc: 0.7650 - val_loss: 0.5213 - val_acc: 0.8025\n",
      "Epoch 85/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.5199 - acc: 0.7650 - val_loss: 0.5225 - val_acc: 0.8013\n",
      "Epoch 86/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.5204 - acc: 0.7550 - val_loss: 0.5241 - val_acc: 0.8025\n",
      "Epoch 87/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.5166 - acc: 0.7650 - val_loss: 0.5193 - val_acc: 0.8063\n",
      "Epoch 88/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.5152 - acc: 0.7700 - val_loss: 0.5140 - val_acc: 0.8113\n",
      "Epoch 89/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.5127 - acc: 0.7600 - val_loss: 0.5123 - val_acc: 0.8100\n",
      "Epoch 90/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.5107 - acc: 0.7650 - val_loss: 0.5121 - val_acc: 0.8087\n",
      "Epoch 91/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.5087 - acc: 0.7650 - val_loss: 0.5100 - val_acc: 0.8100\n",
      "Epoch 92/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.5069 - acc: 0.7650 - val_loss: 0.5077 - val_acc: 0.8125\n",
      "Epoch 93/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.5056 - acc: 0.7650 - val_loss: 0.5073 - val_acc: 0.8087\n",
      "Epoch 94/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.5030 - acc: 0.7650 - val_loss: 0.5057 - val_acc: 0.8100\n",
      "Epoch 95/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.5016 - acc: 0.7650 - val_loss: 0.5035 - val_acc: 0.8087\n",
      "Epoch 96/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4997 - acc: 0.7650 - val_loss: 0.4981 - val_acc: 0.8113\n",
      "Epoch 97/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.4976 - acc: 0.7650 - val_loss: 0.4978 - val_acc: 0.8100\n",
      "Epoch 98/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4956 - acc: 0.7600 - val_loss: 0.4957 - val_acc: 0.8113\n",
      "Epoch 99/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4943 - acc: 0.7600 - val_loss: 0.4954 - val_acc: 0.8175\n",
      "Epoch 100/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.4916 - acc: 0.7600 - val_loss: 0.4919 - val_acc: 0.8200\n",
      "Epoch 101/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4915 - acc: 0.7650 - val_loss: 0.4877 - val_acc: 0.8213\n",
      "Epoch 102/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.4889 - acc: 0.7800 - val_loss: 0.4853 - val_acc: 0.8225\n",
      "Epoch 103/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.4859 - acc: 0.7750 - val_loss: 0.4865 - val_acc: 0.8250\n",
      "Epoch 104/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4848 - acc: 0.7750 - val_loss: 0.4872 - val_acc: 0.8225\n",
      "Epoch 105/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.4835 - acc: 0.7800 - val_loss: 0.4852 - val_acc: 0.8200\n",
      "Epoch 106/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.4819 - acc: 0.7850 - val_loss: 0.4825 - val_acc: 0.8237\n",
      "Epoch 107/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.4809 - acc: 0.7850 - val_loss: 0.4793 - val_acc: 0.8275\n",
      "Epoch 108/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4789 - acc: 0.7900 - val_loss: 0.4759 - val_acc: 0.8287\n",
      "Epoch 109/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.4778 - acc: 0.7850 - val_loss: 0.4744 - val_acc: 0.8300\n",
      "Epoch 110/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.4767 - acc: 0.7850 - val_loss: 0.4744 - val_acc: 0.8287\n",
      "Epoch 111/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.4751 - acc: 0.7850 - val_loss: 0.4730 - val_acc: 0.8275\n",
      "Epoch 112/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4739 - acc: 0.7850 - val_loss: 0.4725 - val_acc: 0.8275\n",
      "Epoch 113/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4725 - acc: 0.7850 - val_loss: 0.4700 - val_acc: 0.8287\n",
      "Epoch 114/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4712 - acc: 0.7850 - val_loss: 0.4707 - val_acc: 0.8300\n",
      "Epoch 115/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4706 - acc: 0.7800 - val_loss: 0.4701 - val_acc: 0.8287\n",
      "Epoch 116/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.4695 - acc: 0.7800 - val_loss: 0.4682 - val_acc: 0.8275\n",
      "Epoch 117/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.4682 - acc: 0.7900 - val_loss: 0.4677 - val_acc: 0.8313\n",
      "Epoch 118/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.4674 - acc: 0.7950 - val_loss: 0.4659 - val_acc: 0.8363\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 143us/step - loss: 0.4663 - acc: 0.7900 - val_loss: 0.4649 - val_acc: 0.8337\n",
      "Epoch 120/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4649 - acc: 0.7850 - val_loss: 0.4634 - val_acc: 0.8350\n",
      "Epoch 121/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4646 - acc: 0.7950 - val_loss: 0.4622 - val_acc: 0.8375\n",
      "Epoch 122/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.4640 - acc: 0.7950 - val_loss: 0.4571 - val_acc: 0.8350\n",
      "Epoch 123/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4627 - acc: 0.7800 - val_loss: 0.4548 - val_acc: 0.8350\n",
      "Epoch 124/1000\n",
      "200/200 [==============================] - 0s 175us/step - loss: 0.4627 - acc: 0.7850 - val_loss: 0.4530 - val_acc: 0.8337\n",
      "Epoch 125/1000\n",
      "200/200 [==============================] - 0s 165us/step - loss: 0.4612 - acc: 0.7800 - val_loss: 0.4534 - val_acc: 0.8363\n",
      "Epoch 126/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4599 - acc: 0.7900 - val_loss: 0.4547 - val_acc: 0.8350\n",
      "Epoch 127/1000\n",
      "200/200 [==============================] - 0s 161us/step - loss: 0.4590 - acc: 0.7950 - val_loss: 0.4586 - val_acc: 0.8350\n",
      "Epoch 128/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4588 - acc: 0.7950 - val_loss: 0.4589 - val_acc: 0.8300\n",
      "Epoch 129/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4579 - acc: 0.7900 - val_loss: 0.4561 - val_acc: 0.8363\n",
      "Epoch 130/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4561 - acc: 0.7950 - val_loss: 0.4561 - val_acc: 0.8325\n",
      "Epoch 131/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.4575 - acc: 0.8050 - val_loss: 0.4588 - val_acc: 0.8313\n",
      "Epoch 132/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.4556 - acc: 0.8050 - val_loss: 0.4543 - val_acc: 0.8350\n",
      "Epoch 133/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4543 - acc: 0.8000 - val_loss: 0.4531 - val_acc: 0.8387\n",
      "Epoch 134/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4525 - acc: 0.7950 - val_loss: 0.4498 - val_acc: 0.8375\n",
      "Epoch 135/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.4529 - acc: 0.8050 - val_loss: 0.4478 - val_acc: 0.8363\n",
      "Epoch 136/1000\n",
      "200/200 [==============================] - 0s 164us/step - loss: 0.4536 - acc: 0.8050 - val_loss: 0.4478 - val_acc: 0.8363\n",
      "Epoch 137/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.4523 - acc: 0.7950 - val_loss: 0.4498 - val_acc: 0.8387\n",
      "Epoch 138/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4503 - acc: 0.7900 - val_loss: 0.4514 - val_acc: 0.8337\n",
      "Epoch 139/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4499 - acc: 0.7950 - val_loss: 0.4500 - val_acc: 0.8350\n",
      "Epoch 140/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4490 - acc: 0.8000 - val_loss: 0.4492 - val_acc: 0.8337\n",
      "Epoch 141/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4489 - acc: 0.8000 - val_loss: 0.4479 - val_acc: 0.8350\n",
      "Epoch 142/1000\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.4478 - acc: 0.8000 - val_loss: 0.4484 - val_acc: 0.8337\n",
      "Epoch 143/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.4475 - acc: 0.8000 - val_loss: 0.4480 - val_acc: 0.8337\n",
      "Epoch 144/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.4467 - acc: 0.8050 - val_loss: 0.4457 - val_acc: 0.8400\n",
      "Epoch 145/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4464 - acc: 0.7950 - val_loss: 0.4422 - val_acc: 0.8387\n",
      "Epoch 146/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4464 - acc: 0.7950 - val_loss: 0.4420 - val_acc: 0.8400\n",
      "Epoch 147/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4457 - acc: 0.7950 - val_loss: 0.4414 - val_acc: 0.8400\n",
      "Epoch 148/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4447 - acc: 0.7950 - val_loss: 0.4410 - val_acc: 0.8387\n",
      "Epoch 149/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.4443 - acc: 0.7900 - val_loss: 0.4407 - val_acc: 0.8400\n",
      "Epoch 150/1000\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.4434 - acc: 0.7950 - val_loss: 0.4433 - val_acc: 0.8337\n",
      "Epoch 151/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4439 - acc: 0.8100 - val_loss: 0.4447 - val_acc: 0.8337\n",
      "Epoch 152/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.4432 - acc: 0.8150 - val_loss: 0.4425 - val_acc: 0.8363\n",
      "Epoch 153/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4422 - acc: 0.8100 - val_loss: 0.4399 - val_acc: 0.8363\n",
      "Epoch 154/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.4418 - acc: 0.8100 - val_loss: 0.4395 - val_acc: 0.8375\n",
      "Epoch 155/1000\n",
      "200/200 [==============================] - 0s 201us/step - loss: 0.4413 - acc: 0.8100 - val_loss: 0.4369 - val_acc: 0.8375\n",
      "Epoch 156/1000\n",
      "200/200 [==============================] - 0s 185us/step - loss: 0.4396 - acc: 0.8000 - val_loss: 0.4331 - val_acc: 0.8375\n",
      "Epoch 157/1000\n",
      "200/200 [==============================] - 0s 180us/step - loss: 0.4414 - acc: 0.7950 - val_loss: 0.4330 - val_acc: 0.8375\n",
      "Epoch 158/1000\n",
      "200/200 [==============================] - 0s 154us/step - loss: 0.4405 - acc: 0.7950 - val_loss: 0.4348 - val_acc: 0.8375\n",
      "Epoch 159/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4391 - acc: 0.7950 - val_loss: 0.4386 - val_acc: 0.8363\n",
      "Epoch 160/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4387 - acc: 0.8150 - val_loss: 0.4413 - val_acc: 0.8313\n",
      "Epoch 161/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4384 - acc: 0.8150 - val_loss: 0.4383 - val_acc: 0.8325\n",
      "Epoch 162/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.4381 - acc: 0.8150 - val_loss: 0.4401 - val_acc: 0.8287\n",
      "Epoch 163/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.4372 - acc: 0.8050 - val_loss: 0.4387 - val_acc: 0.8313\n",
      "Epoch 164/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4365 - acc: 0.8050 - val_loss: 0.4394 - val_acc: 0.8287\n",
      "Epoch 165/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.4354 - acc: 0.8050 - val_loss: 0.4363 - val_acc: 0.8350\n",
      "Epoch 166/1000\n",
      "200/200 [==============================] - 0s 156us/step - loss: 0.4365 - acc: 0.7900 - val_loss: 0.4363 - val_acc: 0.8325\n",
      "Epoch 167/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4354 - acc: 0.7950 - val_loss: 0.4368 - val_acc: 0.8337\n",
      "Epoch 168/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.4347 - acc: 0.8050 - val_loss: 0.4375 - val_acc: 0.8313\n",
      "Epoch 169/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.4347 - acc: 0.8050 - val_loss: 0.4370 - val_acc: 0.8313\n",
      "Epoch 170/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4339 - acc: 0.8050 - val_loss: 0.4362 - val_acc: 0.8337\n",
      "Epoch 171/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4348 - acc: 0.8100 - val_loss: 0.4382 - val_acc: 0.8300\n",
      "Epoch 172/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4331 - acc: 0.8150 - val_loss: 0.4325 - val_acc: 0.8363\n",
      "Epoch 173/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4334 - acc: 0.8000 - val_loss: 0.4295 - val_acc: 0.8375\n",
      "Epoch 174/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.4332 - acc: 0.7900 - val_loss: 0.4288 - val_acc: 0.8375\n",
      "Epoch 175/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4322 - acc: 0.7950 - val_loss: 0.4310 - val_acc: 0.8375\n",
      "Epoch 176/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.4313 - acc: 0.8100 - val_loss: 0.4346 - val_acc: 0.8300\n",
      "Epoch 177/1000\n",
      "200/200 [==============================] - 0s 198us/step - loss: 0.4330 - acc: 0.8200 - val_loss: 0.4402 - val_acc: 0.8337\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 157us/step - loss: 0.4329 - acc: 0.8200 - val_loss: 0.4376 - val_acc: 0.8337\n",
      "Epoch 179/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4315 - acc: 0.8150 - val_loss: 0.4327 - val_acc: 0.8300\n",
      "Epoch 180/1000\n",
      "200/200 [==============================] - 0s 165us/step - loss: 0.4307 - acc: 0.8100 - val_loss: 0.4291 - val_acc: 0.8375\n",
      "Epoch 181/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4300 - acc: 0.8100 - val_loss: 0.4288 - val_acc: 0.8363\n",
      "Epoch 182/1000\n",
      "200/200 [==============================] - 0s 160us/step - loss: 0.4301 - acc: 0.8100 - val_loss: 0.4273 - val_acc: 0.8375\n",
      "Epoch 183/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.4294 - acc: 0.8100 - val_loss: 0.4279 - val_acc: 0.8350\n",
      "Epoch 184/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4285 - acc: 0.8100 - val_loss: 0.4273 - val_acc: 0.8363\n",
      "Epoch 185/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4303 - acc: 0.7950 - val_loss: 0.4277 - val_acc: 0.8350\n",
      "Epoch 186/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4306 - acc: 0.8000 - val_loss: 0.4287 - val_acc: 0.8325\n",
      "Epoch 187/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.4302 - acc: 0.8000 - val_loss: 0.4296 - val_acc: 0.8325\n",
      "Epoch 188/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4278 - acc: 0.8100 - val_loss: 0.4291 - val_acc: 0.8325\n",
      "Epoch 189/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.4278 - acc: 0.8050 - val_loss: 0.4273 - val_acc: 0.8325\n",
      "Epoch 190/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4287 - acc: 0.7950 - val_loss: 0.4267 - val_acc: 0.8337\n",
      "Epoch 191/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.4271 - acc: 0.8000 - val_loss: 0.4288 - val_acc: 0.8337\n",
      "Epoch 192/1000\n",
      "200/200 [==============================] - 0s 163us/step - loss: 0.4262 - acc: 0.8100 - val_loss: 0.4307 - val_acc: 0.8300\n",
      "Epoch 193/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.4265 - acc: 0.8100 - val_loss: 0.4288 - val_acc: 0.8313\n",
      "Epoch 194/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4261 - acc: 0.8100 - val_loss: 0.4286 - val_acc: 0.8313\n",
      "Epoch 195/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4263 - acc: 0.8050 - val_loss: 0.4277 - val_acc: 0.8325\n",
      "Epoch 196/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4257 - acc: 0.8100 - val_loss: 0.4265 - val_acc: 0.8337\n",
      "Epoch 197/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4241 - acc: 0.8100 - val_loss: 0.4295 - val_acc: 0.8263\n",
      "Epoch 198/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4256 - acc: 0.8150 - val_loss: 0.4301 - val_acc: 0.8263\n",
      "Epoch 199/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.4257 - acc: 0.8100 - val_loss: 0.4253 - val_acc: 0.8337\n",
      "Epoch 200/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.4246 - acc: 0.8100 - val_loss: 0.4256 - val_acc: 0.8363\n",
      "Epoch 201/1000\n",
      "200/200 [==============================] - 0s 172us/step - loss: 0.4245 - acc: 0.8100 - val_loss: 0.4256 - val_acc: 0.8350\n",
      "Epoch 202/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.4243 - acc: 0.8100 - val_loss: 0.4247 - val_acc: 0.8363\n",
      "Epoch 203/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.4238 - acc: 0.8100 - val_loss: 0.4229 - val_acc: 0.8350\n",
      "Epoch 204/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.4236 - acc: 0.8100 - val_loss: 0.4223 - val_acc: 0.8350\n",
      "Epoch 205/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4239 - acc: 0.8050 - val_loss: 0.4217 - val_acc: 0.8325\n",
      "Epoch 206/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5449 - acc: 0.750 - 0s 193us/step - loss: 0.4235 - acc: 0.8100 - val_loss: 0.4226 - val_acc: 0.8325\n",
      "Epoch 207/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4226 - acc: 0.8100 - val_loss: 0.4245 - val_acc: 0.8325\n",
      "Epoch 208/1000\n",
      "200/200 [==============================] - 0s 168us/step - loss: 0.4230 - acc: 0.8150 - val_loss: 0.4258 - val_acc: 0.8263\n",
      "Epoch 209/1000\n",
      "200/200 [==============================] - 0s 179us/step - loss: 0.4230 - acc: 0.8150 - val_loss: 0.4260 - val_acc: 0.8263\n",
      "Epoch 210/1000\n",
      "200/200 [==============================] - 0s 162us/step - loss: 0.4217 - acc: 0.8150 - val_loss: 0.4222 - val_acc: 0.8350\n",
      "Epoch 211/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4220 - acc: 0.8100 - val_loss: 0.4193 - val_acc: 0.8350\n",
      "Epoch 212/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.4225 - acc: 0.8100 - val_loss: 0.4184 - val_acc: 0.8325\n",
      "Epoch 213/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4219 - acc: 0.8100 - val_loss: 0.4228 - val_acc: 0.8275\n",
      "Epoch 214/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4218 - acc: 0.8200 - val_loss: 0.4238 - val_acc: 0.8250\n",
      "Epoch 215/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4201 - acc: 0.8200 - val_loss: 0.4189 - val_acc: 0.8337\n",
      "Epoch 216/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.4211 - acc: 0.8100 - val_loss: 0.4184 - val_acc: 0.8363\n",
      "Epoch 217/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4210 - acc: 0.8050 - val_loss: 0.4199 - val_acc: 0.8363\n",
      "Epoch 218/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4201 - acc: 0.8100 - val_loss: 0.4226 - val_acc: 0.8325\n",
      "Epoch 219/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4196 - acc: 0.8100 - val_loss: 0.4240 - val_acc: 0.8313\n",
      "Epoch 220/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4198 - acc: 0.8150 - val_loss: 0.4276 - val_acc: 0.8287\n",
      "Epoch 221/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.4203 - acc: 0.8200 - val_loss: 0.4281 - val_acc: 0.8300\n",
      "Epoch 222/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.4195 - acc: 0.8200 - val_loss: 0.4241 - val_acc: 0.8350\n",
      "Epoch 223/1000\n",
      "200/200 [==============================] - 0s 102us/step - loss: 0.4197 - acc: 0.8100 - val_loss: 0.4212 - val_acc: 0.8350\n",
      "Epoch 224/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4190 - acc: 0.8100 - val_loss: 0.4221 - val_acc: 0.8350\n",
      "Epoch 225/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4184 - acc: 0.8100 - val_loss: 0.4222 - val_acc: 0.8300\n",
      "Epoch 226/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.4183 - acc: 0.8150 - val_loss: 0.4206 - val_acc: 0.8350\n",
      "Epoch 227/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4179 - acc: 0.8100 - val_loss: 0.4204 - val_acc: 0.8313\n",
      "Epoch 228/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4186 - acc: 0.8100 - val_loss: 0.4182 - val_acc: 0.8337\n",
      "Epoch 229/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4183 - acc: 0.8100 - val_loss: 0.4196 - val_acc: 0.8300\n",
      "Epoch 230/1000\n",
      "200/200 [==============================] - 0s 101us/step - loss: 0.4173 - acc: 0.8050 - val_loss: 0.4199 - val_acc: 0.8287\n",
      "Epoch 231/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4172 - acc: 0.8050 - val_loss: 0.4195 - val_acc: 0.8313\n",
      "Epoch 232/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.4169 - acc: 0.8100 - val_loss: 0.4213 - val_acc: 0.8275\n",
      "Epoch 233/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4177 - acc: 0.8150 - val_loss: 0.4213 - val_acc: 0.8313\n",
      "Epoch 234/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4168 - acc: 0.8150 - val_loss: 0.4228 - val_acc: 0.8287\n",
      "Epoch 235/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.4166 - acc: 0.8150 - val_loss: 0.4216 - val_acc: 0.8275\n",
      "Epoch 236/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4184 - acc: 0.8050 - val_loss: 0.4171 - val_acc: 0.8325\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 110us/step - loss: 0.4169 - acc: 0.8100 - val_loss: 0.4173 - val_acc: 0.8337\n",
      "Epoch 238/1000\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.4162 - acc: 0.8050 - val_loss: 0.4196 - val_acc: 0.8325\n",
      "Epoch 239/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4166 - acc: 0.8150 - val_loss: 0.4230 - val_acc: 0.8287\n",
      "Epoch 240/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4152 - acc: 0.8200 - val_loss: 0.4196 - val_acc: 0.8325\n",
      "Epoch 241/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4155 - acc: 0.8100 - val_loss: 0.4171 - val_acc: 0.8325\n",
      "Epoch 242/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4160 - acc: 0.8050 - val_loss: 0.4174 - val_acc: 0.8300\n",
      "Epoch 243/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4158 - acc: 0.8100 - val_loss: 0.4174 - val_acc: 0.8313\n",
      "Epoch 244/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4157 - acc: 0.8100 - val_loss: 0.4181 - val_acc: 0.8337\n",
      "Epoch 245/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4155 - acc: 0.8100 - val_loss: 0.4181 - val_acc: 0.8300\n",
      "Epoch 246/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4149 - acc: 0.8100 - val_loss: 0.4165 - val_acc: 0.8300\n",
      "Epoch 247/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4148 - acc: 0.8150 - val_loss: 0.4170 - val_acc: 0.8287\n",
      "Epoch 248/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4151 - acc: 0.8150 - val_loss: 0.4194 - val_acc: 0.8263\n",
      "Epoch 249/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4149 - acc: 0.8200 - val_loss: 0.4187 - val_acc: 0.8263\n",
      "Epoch 250/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.4150 - acc: 0.8150 - val_loss: 0.4165 - val_acc: 0.8263\n",
      "Epoch 251/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.4136 - acc: 0.8150 - val_loss: 0.4165 - val_acc: 0.8225\n",
      "Epoch 252/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4139 - acc: 0.8200 - val_loss: 0.4183 - val_acc: 0.8237\n",
      "Epoch 253/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.4141 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8263\n",
      "Epoch 254/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4141 - acc: 0.8150 - val_loss: 0.4174 - val_acc: 0.8263\n",
      "Epoch 255/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4131 - acc: 0.8150 - val_loss: 0.4215 - val_acc: 0.8300\n",
      "Epoch 256/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4144 - acc: 0.8200 - val_loss: 0.4225 - val_acc: 0.8287\n",
      "Epoch 257/1000\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.4164 - acc: 0.8150 - val_loss: 0.4169 - val_acc: 0.8313\n",
      "Epoch 258/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4132 - acc: 0.8150 - val_loss: 0.4181 - val_acc: 0.8300\n",
      "Epoch 259/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4125 - acc: 0.8150 - val_loss: 0.4159 - val_acc: 0.8337\n",
      "Epoch 260/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4127 - acc: 0.8050 - val_loss: 0.4151 - val_acc: 0.8325\n",
      "Epoch 261/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.4130 - acc: 0.8050 - val_loss: 0.4148 - val_acc: 0.8325\n",
      "Epoch 262/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.4139 - acc: 0.8000 - val_loss: 0.4159 - val_acc: 0.8300\n",
      "Epoch 263/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4141 - acc: 0.8000 - val_loss: 0.4168 - val_acc: 0.8300\n",
      "Epoch 264/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.4129 - acc: 0.8050 - val_loss: 0.4185 - val_acc: 0.8275\n",
      "Epoch 265/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4125 - acc: 0.8050 - val_loss: 0.4194 - val_acc: 0.8250\n",
      "Epoch 266/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4133 - acc: 0.8100 - val_loss: 0.4189 - val_acc: 0.8263\n",
      "Epoch 267/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4128 - acc: 0.8000 - val_loss: 0.4204 - val_acc: 0.8263\n",
      "Epoch 268/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4123 - acc: 0.8050 - val_loss: 0.4217 - val_acc: 0.8225\n",
      "Epoch 269/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4128 - acc: 0.8200 - val_loss: 0.4227 - val_acc: 0.8237\n",
      "Epoch 270/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4114 - acc: 0.8200 - val_loss: 0.4196 - val_acc: 0.8263\n",
      "Epoch 271/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4110 - acc: 0.8100 - val_loss: 0.4150 - val_acc: 0.8263\n",
      "Epoch 272/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4112 - acc: 0.8100 - val_loss: 0.4155 - val_acc: 0.8237\n",
      "Epoch 273/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4111 - acc: 0.8100 - val_loss: 0.4160 - val_acc: 0.8250\n",
      "Epoch 274/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4117 - acc: 0.8100 - val_loss: 0.4136 - val_acc: 0.8275\n",
      "Epoch 275/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4110 - acc: 0.8100 - val_loss: 0.4136 - val_acc: 0.8275\n",
      "Epoch 276/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4107 - acc: 0.8100 - val_loss: 0.4136 - val_acc: 0.8275\n",
      "Epoch 277/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.4108 - acc: 0.8100 - val_loss: 0.4151 - val_acc: 0.8250\n",
      "Epoch 278/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.4104 - acc: 0.8100 - val_loss: 0.4145 - val_acc: 0.8263\n",
      "Epoch 279/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.4107 - acc: 0.8100 - val_loss: 0.4142 - val_acc: 0.8275\n",
      "Epoch 280/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.4123 - acc: 0.8150 - val_loss: 0.4184 - val_acc: 0.8287\n",
      "Epoch 281/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4106 - acc: 0.8200 - val_loss: 0.4158 - val_acc: 0.8275\n",
      "Epoch 282/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4106 - acc: 0.8150 - val_loss: 0.4116 - val_acc: 0.8325\n",
      "Epoch 283/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4103 - acc: 0.8150 - val_loss: 0.4116 - val_acc: 0.8337\n",
      "Epoch 284/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.4103 - acc: 0.8100 - val_loss: 0.4118 - val_acc: 0.8337\n",
      "Epoch 285/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.4100 - acc: 0.8100 - val_loss: 0.4111 - val_acc: 0.8325\n",
      "Epoch 286/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4104 - acc: 0.8050 - val_loss: 0.4106 - val_acc: 0.8350\n",
      "Epoch 287/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.4102 - acc: 0.8050 - val_loss: 0.4118 - val_acc: 0.8325\n",
      "Epoch 288/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4109 - acc: 0.8150 - val_loss: 0.4146 - val_acc: 0.8225\n",
      "Epoch 289/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4093 - acc: 0.8150 - val_loss: 0.4125 - val_acc: 0.8313\n",
      "Epoch 290/1000\n",
      "200/200 [==============================] - 0s 159us/step - loss: 0.4092 - acc: 0.8150 - val_loss: 0.4136 - val_acc: 0.8263\n",
      "Epoch 291/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.4092 - acc: 0.8100 - val_loss: 0.4154 - val_acc: 0.8250\n",
      "Epoch 292/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4103 - acc: 0.8100 - val_loss: 0.4174 - val_acc: 0.8225\n",
      "Epoch 293/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4110 - acc: 0.8100 - val_loss: 0.4147 - val_acc: 0.8313\n",
      "Epoch 294/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.4092 - acc: 0.8100 - val_loss: 0.4148 - val_acc: 0.8313\n",
      "Epoch 295/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4091 - acc: 0.8100 - val_loss: 0.4150 - val_acc: 0.8300\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 117us/step - loss: 0.4087 - acc: 0.8100 - val_loss: 0.4156 - val_acc: 0.8213\n",
      "Epoch 297/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4086 - acc: 0.8100 - val_loss: 0.4164 - val_acc: 0.8250\n",
      "Epoch 298/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.4090 - acc: 0.8100 - val_loss: 0.4168 - val_acc: 0.8275\n",
      "Epoch 299/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.4084 - acc: 0.8100 - val_loss: 0.4161 - val_acc: 0.8275\n",
      "Epoch 300/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4085 - acc: 0.8100 - val_loss: 0.4151 - val_acc: 0.8250\n",
      "Epoch 301/1000\n",
      "200/200 [==============================] - 0s 154us/step - loss: 0.4089 - acc: 0.8050 - val_loss: 0.4118 - val_acc: 0.8275\n",
      "Epoch 302/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4082 - acc: 0.8100 - val_loss: 0.4119 - val_acc: 0.8250\n",
      "Epoch 303/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4082 - acc: 0.8100 - val_loss: 0.4123 - val_acc: 0.8250\n",
      "Epoch 304/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.4083 - acc: 0.8100 - val_loss: 0.4138 - val_acc: 0.8200\n",
      "Epoch 305/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4084 - acc: 0.8050 - val_loss: 0.4166 - val_acc: 0.8250\n",
      "Epoch 306/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4082 - acc: 0.8200 - val_loss: 0.4168 - val_acc: 0.8250\n",
      "Epoch 307/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4086 - acc: 0.8200 - val_loss: 0.4162 - val_acc: 0.8275\n",
      "Epoch 308/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4087 - acc: 0.8200 - val_loss: 0.4194 - val_acc: 0.8225\n",
      "Epoch 309/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4090 - acc: 0.8200 - val_loss: 0.4176 - val_acc: 0.8213\n",
      "Epoch 310/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4088 - acc: 0.8150 - val_loss: 0.4182 - val_acc: 0.8263\n",
      "Epoch 311/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4081 - acc: 0.8200 - val_loss: 0.4174 - val_acc: 0.8263\n",
      "Epoch 312/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4077 - acc: 0.8150 - val_loss: 0.4161 - val_acc: 0.8250\n",
      "Epoch 313/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.4082 - acc: 0.8100 - val_loss: 0.4142 - val_acc: 0.8275\n",
      "Epoch 314/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.4071 - acc: 0.8150 - val_loss: 0.4148 - val_acc: 0.8250\n",
      "Epoch 315/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4074 - acc: 0.8100 - val_loss: 0.4170 - val_acc: 0.8237\n",
      "Epoch 316/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.4083 - acc: 0.8150 - val_loss: 0.4156 - val_acc: 0.8237\n",
      "Epoch 317/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4070 - acc: 0.8200 - val_loss: 0.4143 - val_acc: 0.8225\n",
      "Epoch 318/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4074 - acc: 0.8200 - val_loss: 0.4123 - val_acc: 0.8250\n",
      "Epoch 319/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.4070 - acc: 0.8200 - val_loss: 0.4129 - val_acc: 0.8225\n",
      "Epoch 320/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.4076 - acc: 0.8150 - val_loss: 0.4121 - val_acc: 0.8237\n",
      "Epoch 321/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4064 - acc: 0.8100 - val_loss: 0.4133 - val_acc: 0.8250\n",
      "Epoch 322/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4067 - acc: 0.8100 - val_loss: 0.4133 - val_acc: 0.8263\n",
      "Epoch 323/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4066 - acc: 0.8100 - val_loss: 0.4125 - val_acc: 0.8263\n",
      "Epoch 324/1000\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.4073 - acc: 0.8100 - val_loss: 0.4116 - val_acc: 0.8250\n",
      "Epoch 325/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4074 - acc: 0.8150 - val_loss: 0.4141 - val_acc: 0.8250\n",
      "Epoch 326/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4064 - acc: 0.8150 - val_loss: 0.4143 - val_acc: 0.8237\n",
      "Epoch 327/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4058 - acc: 0.8150 - val_loss: 0.4153 - val_acc: 0.8250\n",
      "Epoch 328/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4143 - acc: 0.843 - 0s 112us/step - loss: 0.4065 - acc: 0.8200 - val_loss: 0.4167 - val_acc: 0.8250\n",
      "Epoch 329/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4068 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8263\n",
      "Epoch 330/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4060 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8237\n",
      "Epoch 331/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.4067 - acc: 0.8150 - val_loss: 0.4127 - val_acc: 0.8263\n",
      "Epoch 332/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4064 - acc: 0.8100 - val_loss: 0.4150 - val_acc: 0.8175\n",
      "Epoch 333/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4065 - acc: 0.8150 - val_loss: 0.4159 - val_acc: 0.8213\n",
      "Epoch 334/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4062 - acc: 0.8250 - val_loss: 0.4164 - val_acc: 0.8213\n",
      "Epoch 335/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.4076 - acc: 0.8250 - val_loss: 0.4175 - val_acc: 0.8225\n",
      "Epoch 336/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4064 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8200\n",
      "Epoch 337/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4059 - acc: 0.8200 - val_loss: 0.4143 - val_acc: 0.8187\n",
      "Epoch 338/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4060 - acc: 0.8200 - val_loss: 0.4155 - val_acc: 0.8200\n",
      "Epoch 339/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.4061 - acc: 0.8100 - val_loss: 0.4137 - val_acc: 0.8225\n",
      "Epoch 340/1000\n",
      "200/200 [==============================] - 0s 207us/step - loss: 0.4051 - acc: 0.8100 - val_loss: 0.4130 - val_acc: 0.8250\n",
      "Epoch 341/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4053 - acc: 0.8150 - val_loss: 0.4136 - val_acc: 0.8213\n",
      "Epoch 342/1000\n",
      "200/200 [==============================] - 0s 156us/step - loss: 0.4052 - acc: 0.8100 - val_loss: 0.4132 - val_acc: 0.8250\n",
      "Epoch 343/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.4052 - acc: 0.8150 - val_loss: 0.4128 - val_acc: 0.8213\n",
      "Epoch 344/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4049 - acc: 0.8050 - val_loss: 0.4120 - val_acc: 0.8200\n",
      "Epoch 345/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.4051 - acc: 0.8100 - val_loss: 0.4138 - val_acc: 0.8225\n",
      "Epoch 346/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4049 - acc: 0.8150 - val_loss: 0.4136 - val_acc: 0.8225\n",
      "Epoch 347/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4049 - acc: 0.8100 - val_loss: 0.4122 - val_acc: 0.8213\n",
      "Epoch 348/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.4051 - acc: 0.8150 - val_loss: 0.4135 - val_acc: 0.8213\n",
      "Epoch 349/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4048 - acc: 0.8150 - val_loss: 0.4119 - val_acc: 0.8200\n",
      "Epoch 350/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4046 - acc: 0.8100 - val_loss: 0.4100 - val_acc: 0.8213\n",
      "Epoch 351/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.4042 - acc: 0.8050 - val_loss: 0.4078 - val_acc: 0.8275\n",
      "Epoch 352/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.4052 - acc: 0.8050 - val_loss: 0.4074 - val_acc: 0.8300\n",
      "Epoch 353/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4085 - acc: 0.843 - 0s 139us/step - loss: 0.4056 - acc: 0.8100 - val_loss: 0.4074 - val_acc: 0.8250\n",
      "Epoch 354/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4049 - acc: 0.8150 - val_loss: 0.4140 - val_acc: 0.8237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4058 - acc: 0.8150 - val_loss: 0.4166 - val_acc: 0.8213\n",
      "Epoch 356/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4056 - acc: 0.8150 - val_loss: 0.4161 - val_acc: 0.8213\n",
      "Epoch 357/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4052 - acc: 0.8150 - val_loss: 0.4126 - val_acc: 0.8213\n",
      "Epoch 358/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4041 - acc: 0.8200 - val_loss: 0.4132 - val_acc: 0.8225\n",
      "Epoch 359/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4054 - acc: 0.8150 - val_loss: 0.4164 - val_acc: 0.8213\n",
      "Epoch 360/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4047 - acc: 0.8150 - val_loss: 0.4143 - val_acc: 0.8225\n",
      "Epoch 361/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4056 - acc: 0.8100 - val_loss: 0.4111 - val_acc: 0.8250\n",
      "Epoch 362/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4037 - acc: 0.8100 - val_loss: 0.4136 - val_acc: 0.8213\n",
      "Epoch 363/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.4050 - acc: 0.8150 - val_loss: 0.4157 - val_acc: 0.8250\n",
      "Epoch 364/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.4059 - acc: 0.8150 - val_loss: 0.4124 - val_acc: 0.8250\n",
      "Epoch 365/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4038 - acc: 0.8150 - val_loss: 0.4124 - val_acc: 0.8237\n",
      "Epoch 366/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4033 - acc: 0.8150 - val_loss: 0.4126 - val_acc: 0.8225\n",
      "Epoch 367/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4035 - acc: 0.8100 - val_loss: 0.4135 - val_acc: 0.8225\n",
      "Epoch 368/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4038 - acc: 0.8100 - val_loss: 0.4126 - val_acc: 0.8225\n",
      "Epoch 369/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.4035 - acc: 0.8100 - val_loss: 0.4109 - val_acc: 0.8237\n",
      "Epoch 370/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4045 - acc: 0.8100 - val_loss: 0.4110 - val_acc: 0.8213\n",
      "Epoch 371/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4040 - acc: 0.8200 - val_loss: 0.4123 - val_acc: 0.8263\n",
      "Epoch 372/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4035 - acc: 0.8200 - val_loss: 0.4127 - val_acc: 0.8237\n",
      "Epoch 373/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4033 - acc: 0.8200 - val_loss: 0.4115 - val_acc: 0.8225\n",
      "Epoch 374/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.4031 - acc: 0.8150 - val_loss: 0.4118 - val_acc: 0.8213\n",
      "Epoch 375/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4033 - acc: 0.8150 - val_loss: 0.4129 - val_acc: 0.8225\n",
      "Epoch 376/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4037 - acc: 0.8150 - val_loss: 0.4141 - val_acc: 0.8225\n",
      "Epoch 377/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4031 - acc: 0.8200 - val_loss: 0.4124 - val_acc: 0.8200\n",
      "Epoch 378/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4028 - acc: 0.8150 - val_loss: 0.4115 - val_acc: 0.8213\n",
      "Epoch 379/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4024 - acc: 0.8150 - val_loss: 0.4115 - val_acc: 0.8237\n",
      "Epoch 380/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4024 - acc: 0.8150 - val_loss: 0.4123 - val_acc: 0.8237\n",
      "Epoch 381/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4033 - acc: 0.8150 - val_loss: 0.4154 - val_acc: 0.8200\n",
      "Epoch 382/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4031 - acc: 0.8150 - val_loss: 0.4164 - val_acc: 0.8213\n",
      "Epoch 383/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.4035 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8200\n",
      "Epoch 384/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4023 - acc: 0.8150 - val_loss: 0.4143 - val_acc: 0.8213\n",
      "Epoch 385/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4029 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8225\n",
      "Epoch 386/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4031 - acc: 0.8150 - val_loss: 0.4120 - val_acc: 0.8237\n",
      "Epoch 387/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4023 - acc: 0.8150 - val_loss: 0.4112 - val_acc: 0.8263\n",
      "Epoch 388/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4024 - acc: 0.8100 - val_loss: 0.4118 - val_acc: 0.8250\n",
      "Epoch 389/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4026 - acc: 0.8150 - val_loss: 0.4146 - val_acc: 0.8250\n",
      "Epoch 390/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.4030 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8250\n",
      "Epoch 391/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4027 - acc: 0.8150 - val_loss: 0.4127 - val_acc: 0.8237\n",
      "Epoch 392/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4024 - acc: 0.8150 - val_loss: 0.4106 - val_acc: 0.8213\n",
      "Epoch 393/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4027 - acc: 0.8100 - val_loss: 0.4099 - val_acc: 0.8225\n",
      "Epoch 394/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4021 - acc: 0.8100 - val_loss: 0.4114 - val_acc: 0.8225\n",
      "Epoch 395/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.4021 - acc: 0.8100 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 396/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.4017 - acc: 0.8100 - val_loss: 0.4105 - val_acc: 0.8237\n",
      "Epoch 397/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4016 - acc: 0.8100 - val_loss: 0.4121 - val_acc: 0.8213\n",
      "Epoch 398/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.4031 - acc: 0.8150 - val_loss: 0.4115 - val_acc: 0.8237\n",
      "Epoch 399/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4022 - acc: 0.8150 - val_loss: 0.4106 - val_acc: 0.8250\n",
      "Epoch 400/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.4013 - acc: 0.8100 - val_loss: 0.4103 - val_acc: 0.8237\n",
      "Epoch 401/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.4018 - acc: 0.8100 - val_loss: 0.4115 - val_acc: 0.8237\n",
      "Epoch 402/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.4016 - acc: 0.8150 - val_loss: 0.4143 - val_acc: 0.8225\n",
      "Epoch 403/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4020 - acc: 0.8150 - val_loss: 0.4172 - val_acc: 0.8213\n",
      "Epoch 404/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.4033 - acc: 0.8200 - val_loss: 0.4195 - val_acc: 0.8213\n",
      "Epoch 405/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4026 - acc: 0.8200 - val_loss: 0.4166 - val_acc: 0.8225\n",
      "Epoch 406/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4012 - acc: 0.8150 - val_loss: 0.4128 - val_acc: 0.8225\n",
      "Epoch 407/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4022 - acc: 0.8100 - val_loss: 0.4114 - val_acc: 0.8225\n",
      "Epoch 408/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.4025 - acc: 0.8100 - val_loss: 0.4109 - val_acc: 0.8237\n",
      "Epoch 409/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.4010 - acc: 0.8100 - val_loss: 0.4138 - val_acc: 0.8237\n",
      "Epoch 410/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.4012 - acc: 0.8150 - val_loss: 0.4154 - val_acc: 0.8225\n",
      "Epoch 411/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4013 - acc: 0.8150 - val_loss: 0.4151 - val_acc: 0.8263\n",
      "Epoch 412/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4013 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8250\n",
      "Epoch 413/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.4011 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8263\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 115us/step - loss: 0.4057 - acc: 0.8250 - val_loss: 0.4213 - val_acc: 0.8187\n",
      "Epoch 415/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.4027 - acc: 0.8250 - val_loss: 0.4135 - val_acc: 0.8213\n",
      "Epoch 416/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4014 - acc: 0.8150 - val_loss: 0.4106 - val_acc: 0.8213\n",
      "Epoch 417/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.4011 - acc: 0.8150 - val_loss: 0.4119 - val_acc: 0.8225\n",
      "Epoch 418/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.4008 - acc: 0.8150 - val_loss: 0.4118 - val_acc: 0.8213\n",
      "Epoch 419/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.4009 - acc: 0.8150 - val_loss: 0.4137 - val_acc: 0.8213\n",
      "Epoch 420/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.4008 - acc: 0.8100 - val_loss: 0.4135 - val_acc: 0.8200\n",
      "Epoch 421/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.4004 - acc: 0.8150 - val_loss: 0.4116 - val_acc: 0.8225\n",
      "Epoch 422/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.4009 - acc: 0.8150 - val_loss: 0.4119 - val_acc: 0.8225\n",
      "Epoch 423/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4008 - acc: 0.8200 - val_loss: 0.4121 - val_acc: 0.8213\n",
      "Epoch 424/1000\n",
      "200/200 [==============================] - 0s 208us/step - loss: 0.4010 - acc: 0.8200 - val_loss: 0.4126 - val_acc: 0.8213\n",
      "Epoch 425/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.4006 - acc: 0.8200 - val_loss: 0.4140 - val_acc: 0.8225\n",
      "Epoch 426/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.4010 - acc: 0.8200 - val_loss: 0.4124 - val_acc: 0.8213\n",
      "Epoch 427/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.4017 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8225\n",
      "Epoch 428/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.4005 - acc: 0.8200 - val_loss: 0.4159 - val_acc: 0.8213\n",
      "Epoch 429/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.4004 - acc: 0.8200 - val_loss: 0.4155 - val_acc: 0.8237\n",
      "Epoch 430/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.4004 - acc: 0.8200 - val_loss: 0.4148 - val_acc: 0.8225\n",
      "Epoch 431/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.4007 - acc: 0.8200 - val_loss: 0.4134 - val_acc: 0.8213\n",
      "Epoch 432/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4010 - acc: 0.8250 - val_loss: 0.4135 - val_acc: 0.8225\n",
      "Epoch 433/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.4006 - acc: 0.8200 - val_loss: 0.4141 - val_acc: 0.8213\n",
      "Epoch 434/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4001 - acc: 0.8150 - val_loss: 0.4138 - val_acc: 0.8225\n",
      "Epoch 435/1000\n",
      "200/200 [==============================] - 0s 154us/step - loss: 0.4001 - acc: 0.8150 - val_loss: 0.4146 - val_acc: 0.8213\n",
      "Epoch 436/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.3997 - acc: 0.8150 - val_loss: 0.4138 - val_acc: 0.8225\n",
      "Epoch 437/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3998 - acc: 0.8150 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 438/1000\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.4004 - acc: 0.8150 - val_loss: 0.4100 - val_acc: 0.8225\n",
      "Epoch 439/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.4003 - acc: 0.8100 - val_loss: 0.4099 - val_acc: 0.8225\n",
      "Epoch 440/1000\n",
      "200/200 [==============================] - 0s 96us/step - loss: 0.4008 - acc: 0.8100 - val_loss: 0.4117 - val_acc: 0.8237\n",
      "Epoch 441/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3998 - acc: 0.8150 - val_loss: 0.4141 - val_acc: 0.8225\n",
      "Epoch 442/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.3997 - acc: 0.8150 - val_loss: 0.4155 - val_acc: 0.8237\n",
      "Epoch 443/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.4005 - acc: 0.8200 - val_loss: 0.4166 - val_acc: 0.8237\n",
      "Epoch 444/1000\n",
      "200/200 [==============================] - 0s 167us/step - loss: 0.3997 - acc: 0.8200 - val_loss: 0.4124 - val_acc: 0.8263\n",
      "Epoch 445/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3996 - acc: 0.8150 - val_loss: 0.4123 - val_acc: 0.8237\n",
      "Epoch 446/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.4005 - acc: 0.8150 - val_loss: 0.4155 - val_acc: 0.8200\n",
      "Epoch 447/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.4000 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8200\n",
      "Epoch 448/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.4001 - acc: 0.8200 - val_loss: 0.4131 - val_acc: 0.8225\n",
      "Epoch 449/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.4028 - acc: 0.8050 - val_loss: 0.4109 - val_acc: 0.8300\n",
      "Epoch 450/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4042 - acc: 0.7950 - val_loss: 0.4108 - val_acc: 0.8325\n",
      "Epoch 451/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.4022 - acc: 0.8000 - val_loss: 0.4110 - val_acc: 0.8287\n",
      "Epoch 452/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.4000 - acc: 0.8100 - val_loss: 0.4122 - val_acc: 0.8250\n",
      "Epoch 453/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3996 - acc: 0.8150 - val_loss: 0.4162 - val_acc: 0.8225\n",
      "Epoch 454/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3998 - acc: 0.8150 - val_loss: 0.4163 - val_acc: 0.8187\n",
      "Epoch 455/1000\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.4003 - acc: 0.8150 - val_loss: 0.4161 - val_acc: 0.8200\n",
      "Epoch 456/1000\n",
      "200/200 [==============================] - 0s 159us/step - loss: 0.3997 - acc: 0.8100 - val_loss: 0.4132 - val_acc: 0.8225\n",
      "Epoch 457/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.3991 - acc: 0.8100 - val_loss: 0.4126 - val_acc: 0.8237\n",
      "Epoch 458/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3996 - acc: 0.8100 - val_loss: 0.4126 - val_acc: 0.8237\n",
      "Epoch 459/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3989 - acc: 0.8100 - val_loss: 0.4101 - val_acc: 0.8225\n",
      "Epoch 460/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.3995 - acc: 0.8100 - val_loss: 0.4087 - val_acc: 0.8237\n",
      "Epoch 461/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3997 - acc: 0.8100 - val_loss: 0.4102 - val_acc: 0.8225\n",
      "Epoch 462/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3991 - acc: 0.8100 - val_loss: 0.4100 - val_acc: 0.8225\n",
      "Epoch 463/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3995 - acc: 0.8100 - val_loss: 0.4109 - val_acc: 0.8237\n",
      "Epoch 464/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3986 - acc: 0.8100 - val_loss: 0.4129 - val_acc: 0.8225\n",
      "Epoch 465/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.3985 - acc: 0.8150 - val_loss: 0.4133 - val_acc: 0.8237\n",
      "Epoch 466/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3988 - acc: 0.8150 - val_loss: 0.4150 - val_acc: 0.8237\n",
      "Epoch 467/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.3989 - acc: 0.8150 - val_loss: 0.4166 - val_acc: 0.8225\n",
      "Epoch 468/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3989 - acc: 0.8200 - val_loss: 0.4158 - val_acc: 0.8237\n",
      "Epoch 469/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3984 - acc: 0.8150 - val_loss: 0.4129 - val_acc: 0.8237\n",
      "Epoch 470/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3990 - acc: 0.8150 - val_loss: 0.4105 - val_acc: 0.8237\n",
      "Epoch 471/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3987 - acc: 0.8100 - val_loss: 0.4108 - val_acc: 0.8237\n",
      "Epoch 472/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.3992 - acc: 0.8100 - val_loss: 0.4097 - val_acc: 0.8250\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 133us/step - loss: 0.3999 - acc: 0.8100 - val_loss: 0.4116 - val_acc: 0.8225\n",
      "Epoch 474/1000\n",
      "200/200 [==============================] - 0s 100us/step - loss: 0.4001 - acc: 0.8100 - val_loss: 0.4092 - val_acc: 0.8250\n",
      "Epoch 475/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3995 - acc: 0.8100 - val_loss: 0.4115 - val_acc: 0.8225\n",
      "Epoch 476/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3985 - acc: 0.8150 - val_loss: 0.4148 - val_acc: 0.8250\n",
      "Epoch 477/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4000 - acc: 0.8200 - val_loss: 0.4167 - val_acc: 0.8250\n",
      "Epoch 478/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3993 - acc: 0.8250 - val_loss: 0.4151 - val_acc: 0.8275\n",
      "Epoch 479/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3986 - acc: 0.8250 - val_loss: 0.4146 - val_acc: 0.8250\n",
      "Epoch 480/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3984 - acc: 0.8200 - val_loss: 0.4114 - val_acc: 0.8250\n",
      "Epoch 481/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3982 - acc: 0.8200 - val_loss: 0.4091 - val_acc: 0.8237\n",
      "Epoch 482/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3992 - acc: 0.8100 - val_loss: 0.4075 - val_acc: 0.8250\n",
      "Epoch 483/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.3995 - acc: 0.8050 - val_loss: 0.4087 - val_acc: 0.8250\n",
      "Epoch 484/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3989 - acc: 0.8100 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 485/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3988 - acc: 0.8100 - val_loss: 0.4127 - val_acc: 0.8225\n",
      "Epoch 486/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3983 - acc: 0.8100 - val_loss: 0.4122 - val_acc: 0.8237\n",
      "Epoch 487/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3982 - acc: 0.8200 - val_loss: 0.4129 - val_acc: 0.8213\n",
      "Epoch 488/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3985 - acc: 0.8150 - val_loss: 0.4122 - val_acc: 0.8237\n",
      "Epoch 489/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3980 - acc: 0.8200 - val_loss: 0.4139 - val_acc: 0.8263\n",
      "Epoch 490/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.4006 - acc: 0.8300 - val_loss: 0.4212 - val_acc: 0.8237\n",
      "Epoch 491/1000\n",
      "200/200 [==============================] - 0s 161us/step - loss: 0.4002 - acc: 0.8300 - val_loss: 0.4157 - val_acc: 0.8225\n",
      "Epoch 492/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.4025 - acc: 0.8150 - val_loss: 0.4082 - val_acc: 0.8213\n",
      "Epoch 493/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3986 - acc: 0.8150 - val_loss: 0.4084 - val_acc: 0.8213\n",
      "Epoch 494/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3979 - acc: 0.8150 - val_loss: 0.4120 - val_acc: 0.8213\n",
      "Epoch 495/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3985 - acc: 0.8200 - val_loss: 0.4134 - val_acc: 0.8200\n",
      "Epoch 496/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3984 - acc: 0.8200 - val_loss: 0.4131 - val_acc: 0.8213\n",
      "Epoch 497/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3979 - acc: 0.8200 - val_loss: 0.4112 - val_acc: 0.8237\n",
      "Epoch 498/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3985 - acc: 0.8200 - val_loss: 0.4099 - val_acc: 0.8263\n",
      "Epoch 499/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3988 - acc: 0.8200 - val_loss: 0.4116 - val_acc: 0.8250\n",
      "Epoch 500/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3982 - acc: 0.8200 - val_loss: 0.4118 - val_acc: 0.8250\n",
      "Epoch 501/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.3982 - acc: 0.8200 - val_loss: 0.4120 - val_acc: 0.8237\n",
      "Epoch 502/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3974 - acc: 0.8200 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 503/1000\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.3987 - acc: 0.8150 - val_loss: 0.4077 - val_acc: 0.8225\n",
      "Epoch 504/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3980 - acc: 0.8100 - val_loss: 0.4083 - val_acc: 0.8225\n",
      "Epoch 505/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3975 - acc: 0.8200 - val_loss: 0.4085 - val_acc: 0.8237\n",
      "Epoch 506/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3983 - acc: 0.8150 - val_loss: 0.4083 - val_acc: 0.8237\n",
      "Epoch 507/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3975 - acc: 0.8200 - val_loss: 0.4112 - val_acc: 0.8225\n",
      "Epoch 508/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3976 - acc: 0.8200 - val_loss: 0.4120 - val_acc: 0.8237\n",
      "Epoch 509/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3974 - acc: 0.8250 - val_loss: 0.4112 - val_acc: 0.8225\n",
      "Epoch 510/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.3979 - acc: 0.8200 - val_loss: 0.4112 - val_acc: 0.8213\n",
      "Epoch 511/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3975 - acc: 0.8150 - val_loss: 0.4091 - val_acc: 0.8225\n",
      "Epoch 512/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3977 - acc: 0.8150 - val_loss: 0.4086 - val_acc: 0.8237\n",
      "Epoch 513/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3971 - acc: 0.8150 - val_loss: 0.4127 - val_acc: 0.8237\n",
      "Epoch 514/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3977 - acc: 0.8200 - val_loss: 0.4132 - val_acc: 0.8237\n",
      "Epoch 515/1000\n",
      "200/200 [==============================] - 0s 95us/step - loss: 0.3975 - acc: 0.8200 - val_loss: 0.4105 - val_acc: 0.8213\n",
      "Epoch 516/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3978 - acc: 0.8150 - val_loss: 0.4094 - val_acc: 0.8225\n",
      "Epoch 517/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3972 - acc: 0.8200 - val_loss: 0.4106 - val_acc: 0.8250\n",
      "Epoch 518/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3972 - acc: 0.8200 - val_loss: 0.4116 - val_acc: 0.8225\n",
      "Epoch 519/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3971 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8263\n",
      "Epoch 520/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3972 - acc: 0.8200 - val_loss: 0.4110 - val_acc: 0.8263\n",
      "Epoch 521/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.3969 - acc: 0.8200 - val_loss: 0.4092 - val_acc: 0.8250\n",
      "Epoch 522/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3967 - acc: 0.8150 - val_loss: 0.4080 - val_acc: 0.8213\n",
      "Epoch 523/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3979 - acc: 0.8150 - val_loss: 0.4070 - val_acc: 0.8237\n",
      "Epoch 524/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3974 - acc: 0.8150 - val_loss: 0.4074 - val_acc: 0.8250\n",
      "Epoch 525/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3978 - acc: 0.8150 - val_loss: 0.4089 - val_acc: 0.8225\n",
      "Epoch 526/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.3976 - acc: 0.8150 - val_loss: 0.4086 - val_acc: 0.8237\n",
      "Epoch 527/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3980 - acc: 0.8150 - val_loss: 0.4087 - val_acc: 0.8237\n",
      "Epoch 528/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3987 - acc: 0.8150 - val_loss: 0.4082 - val_acc: 0.8213\n",
      "Epoch 529/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3972 - acc: 0.8150 - val_loss: 0.4098 - val_acc: 0.8225\n",
      "Epoch 530/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.3971 - acc: 0.8150 - val_loss: 0.4100 - val_acc: 0.8237\n",
      "Epoch 531/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3962 - acc: 0.8150 - val_loss: 0.4125 - val_acc: 0.8213\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 131us/step - loss: 0.3969 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8200\n",
      "Epoch 533/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3971 - acc: 0.8200 - val_loss: 0.4148 - val_acc: 0.8213\n",
      "Epoch 534/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3968 - acc: 0.8250 - val_loss: 0.4150 - val_acc: 0.8250\n",
      "Epoch 535/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3974 - acc: 0.8200 - val_loss: 0.4138 - val_acc: 0.8225\n",
      "Epoch 536/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3973 - acc: 0.8200 - val_loss: 0.4144 - val_acc: 0.8250\n",
      "Epoch 537/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3967 - acc: 0.8200 - val_loss: 0.4122 - val_acc: 0.8263\n",
      "Epoch 538/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3963 - acc: 0.8200 - val_loss: 0.4113 - val_acc: 0.8263\n",
      "Epoch 539/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3962 - acc: 0.8150 - val_loss: 0.4089 - val_acc: 0.8300\n",
      "Epoch 540/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3990 - acc: 0.8050 - val_loss: 0.4075 - val_acc: 0.8287\n",
      "Epoch 541/1000\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.3997 - acc: 0.8100 - val_loss: 0.4083 - val_acc: 0.8237\n",
      "Epoch 542/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3971 - acc: 0.8100 - val_loss: 0.4086 - val_acc: 0.8237\n",
      "Epoch 543/1000\n",
      "200/200 [==============================] - 0s 182us/step - loss: 0.3967 - acc: 0.8150 - val_loss: 0.4105 - val_acc: 0.8225\n",
      "Epoch 544/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3971 - acc: 0.8150 - val_loss: 0.4128 - val_acc: 0.8200\n",
      "Epoch 545/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3965 - acc: 0.8150 - val_loss: 0.4121 - val_acc: 0.8200\n",
      "Epoch 546/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3117 - acc: 0.875 - 0s 126us/step - loss: 0.3966 - acc: 0.8150 - val_loss: 0.4132 - val_acc: 0.8213\n",
      "Epoch 547/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3962 - acc: 0.8200 - val_loss: 0.4122 - val_acc: 0.8225\n",
      "Epoch 548/1000\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.3961 - acc: 0.8150 - val_loss: 0.4101 - val_acc: 0.8250\n",
      "Epoch 549/1000\n",
      "200/200 [==============================] - 0s 101us/step - loss: 0.3977 - acc: 0.8100 - val_loss: 0.4095 - val_acc: 0.8237\n",
      "Epoch 550/1000\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.3990 - acc: 0.8100 - val_loss: 0.4108 - val_acc: 0.8225\n",
      "Epoch 551/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3967 - acc: 0.8150 - val_loss: 0.4102 - val_acc: 0.8237\n",
      "Epoch 552/1000\n",
      "200/200 [==============================] - 0s 200us/step - loss: 0.3978 - acc: 0.8150 - val_loss: 0.4104 - val_acc: 0.8250\n",
      "Epoch 553/1000\n",
      "200/200 [==============================] - 0s 162us/step - loss: 0.3974 - acc: 0.8150 - val_loss: 0.4109 - val_acc: 0.8263\n",
      "Epoch 554/1000\n",
      "200/200 [==============================] - 0s 159us/step - loss: 0.3964 - acc: 0.8150 - val_loss: 0.4137 - val_acc: 0.8250\n",
      "Epoch 555/1000\n",
      "200/200 [==============================] - 0s 166us/step - loss: 0.3961 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8225\n",
      "Epoch 556/1000\n",
      "200/200 [==============================] - 0s 199us/step - loss: 0.3965 - acc: 0.8200 - val_loss: 0.4125 - val_acc: 0.8225\n",
      "Epoch 557/1000\n",
      "200/200 [==============================] - 0s 168us/step - loss: 0.3965 - acc: 0.8200 - val_loss: 0.4144 - val_acc: 0.8213\n",
      "Epoch 558/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3967 - acc: 0.8250 - val_loss: 0.4173 - val_acc: 0.8275\n",
      "Epoch 559/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3971 - acc: 0.8250 - val_loss: 0.4172 - val_acc: 0.8250\n",
      "Epoch 560/1000\n",
      "200/200 [==============================] - 0s 209us/step - loss: 0.3972 - acc: 0.8250 - val_loss: 0.4157 - val_acc: 0.8250\n",
      "Epoch 561/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3978 - acc: 0.8250 - val_loss: 0.4178 - val_acc: 0.8250\n",
      "Epoch 562/1000\n",
      "200/200 [==============================] - 0s 160us/step - loss: 0.3967 - acc: 0.8250 - val_loss: 0.4158 - val_acc: 0.8250\n",
      "Epoch 563/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3971 - acc: 0.8200 - val_loss: 0.4117 - val_acc: 0.8250\n",
      "Epoch 564/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3978 - acc: 0.8200 - val_loss: 0.4093 - val_acc: 0.8237\n",
      "Epoch 565/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3963 - acc: 0.8150 - val_loss: 0.4107 - val_acc: 0.8263\n",
      "Epoch 566/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3961 - acc: 0.8150 - val_loss: 0.4118 - val_acc: 0.8237\n",
      "Epoch 567/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.3966 - acc: 0.8150 - val_loss: 0.4132 - val_acc: 0.8225\n",
      "Epoch 568/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3960 - acc: 0.8200 - val_loss: 0.4121 - val_acc: 0.8213\n",
      "Epoch 569/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3957 - acc: 0.8150 - val_loss: 0.4113 - val_acc: 0.8213\n",
      "Epoch 570/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3954 - acc: 0.8150 - val_loss: 0.4125 - val_acc: 0.8237\n",
      "Epoch 571/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.3955 - acc: 0.8150 - val_loss: 0.4132 - val_acc: 0.8250\n",
      "Epoch 572/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3960 - acc: 0.8200 - val_loss: 0.4138 - val_acc: 0.8237\n",
      "Epoch 573/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3972 - acc: 0.8250 - val_loss: 0.4165 - val_acc: 0.8225\n",
      "Epoch 574/1000\n",
      "200/200 [==============================] - 0s 166us/step - loss: 0.3964 - acc: 0.8250 - val_loss: 0.4130 - val_acc: 0.8263\n",
      "Epoch 575/1000\n",
      "200/200 [==============================] - 0s 197us/step - loss: 0.3964 - acc: 0.8200 - val_loss: 0.4110 - val_acc: 0.8263\n",
      "Epoch 576/1000\n",
      "200/200 [==============================] - 0s 177us/step - loss: 0.3952 - acc: 0.8150 - val_loss: 0.4109 - val_acc: 0.8225\n",
      "Epoch 577/1000\n",
      "200/200 [==============================] - 0s 183us/step - loss: 0.3963 - acc: 0.8150 - val_loss: 0.4120 - val_acc: 0.8250\n",
      "Epoch 578/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3961 - acc: 0.8150 - val_loss: 0.4114 - val_acc: 0.8237\n",
      "Epoch 579/1000\n",
      "200/200 [==============================] - 0s 100us/step - loss: 0.3956 - acc: 0.8150 - val_loss: 0.4111 - val_acc: 0.8237\n",
      "Epoch 580/1000\n",
      "200/200 [==============================] - 0s 95us/step - loss: 0.3968 - acc: 0.8150 - val_loss: 0.4094 - val_acc: 0.8237\n",
      "Epoch 581/1000\n",
      "200/200 [==============================] - 0s 98us/step - loss: 0.3970 - acc: 0.8050 - val_loss: 0.4106 - val_acc: 0.8237\n",
      "Epoch 582/1000\n",
      "200/200 [==============================] - 0s 98us/step - loss: 0.3958 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8237\n",
      "Epoch 583/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3970 - acc: 0.8250 - val_loss: 0.4185 - val_acc: 0.8250\n",
      "Epoch 584/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3966 - acc: 0.8250 - val_loss: 0.4168 - val_acc: 0.8275\n",
      "Epoch 585/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3959 - acc: 0.8250 - val_loss: 0.4135 - val_acc: 0.8237\n",
      "Epoch 586/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3955 - acc: 0.8200 - val_loss: 0.4112 - val_acc: 0.8250\n",
      "Epoch 587/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3954 - acc: 0.8150 - val_loss: 0.4113 - val_acc: 0.8237\n",
      "Epoch 588/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3961 - acc: 0.8150 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 589/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3950 - acc: 0.8150 - val_loss: 0.4131 - val_acc: 0.8213\n",
      "Epoch 590/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3961 - acc: 0.8200 - val_loss: 0.4165 - val_acc: 0.8213\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 118us/step - loss: 0.3961 - acc: 0.8200 - val_loss: 0.4145 - val_acc: 0.8250\n",
      "Epoch 592/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3958 - acc: 0.8150 - val_loss: 0.4119 - val_acc: 0.8213\n",
      "Epoch 593/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3952 - acc: 0.8150 - val_loss: 0.4110 - val_acc: 0.8250\n",
      "Epoch 594/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3952 - acc: 0.8150 - val_loss: 0.4101 - val_acc: 0.8250\n",
      "Epoch 595/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3955 - acc: 0.8150 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 596/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3960 - acc: 0.8150 - val_loss: 0.4094 - val_acc: 0.8237\n",
      "Epoch 597/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.3959 - acc: 0.8200 - val_loss: 0.4100 - val_acc: 0.8225\n",
      "Epoch 598/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3957 - acc: 0.8200 - val_loss: 0.4107 - val_acc: 0.8237\n",
      "Epoch 599/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3955 - acc: 0.8200 - val_loss: 0.4114 - val_acc: 0.8250\n",
      "Epoch 600/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.3960 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8275\n",
      "Epoch 601/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3953 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8250\n",
      "Epoch 602/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3959 - acc: 0.8200 - val_loss: 0.4129 - val_acc: 0.8263\n",
      "Epoch 603/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3957 - acc: 0.8200 - val_loss: 0.4125 - val_acc: 0.8263\n",
      "Epoch 604/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3968 - acc: 0.8100 - val_loss: 0.4129 - val_acc: 0.8263\n",
      "Epoch 605/1000\n",
      "200/200 [==============================] - 0s 155us/step - loss: 0.3960 - acc: 0.8200 - val_loss: 0.4139 - val_acc: 0.8275\n",
      "Epoch 606/1000\n",
      "200/200 [==============================] - 0s 177us/step - loss: 0.3953 - acc: 0.8200 - val_loss: 0.4146 - val_acc: 0.8275\n",
      "Epoch 607/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3949 - acc: 0.8200 - val_loss: 0.4154 - val_acc: 0.8275\n",
      "Epoch 608/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3950 - acc: 0.8200 - val_loss: 0.4159 - val_acc: 0.8250\n",
      "Epoch 609/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3949 - acc: 0.8200 - val_loss: 0.4158 - val_acc: 0.8250\n",
      "Epoch 610/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3950 - acc: 0.8250 - val_loss: 0.4146 - val_acc: 0.8263\n",
      "Epoch 611/1000\n",
      "200/200 [==============================] - 0s 165us/step - loss: 0.3958 - acc: 0.8200 - val_loss: 0.4136 - val_acc: 0.8275\n",
      "Epoch 612/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3974 - acc: 0.8100 - val_loss: 0.4096 - val_acc: 0.8237\n",
      "Epoch 613/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3960 - acc: 0.8150 - val_loss: 0.4108 - val_acc: 0.8250\n",
      "Epoch 614/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3955 - acc: 0.8100 - val_loss: 0.4107 - val_acc: 0.8275\n",
      "Epoch 615/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3950 - acc: 0.8150 - val_loss: 0.4098 - val_acc: 0.8275\n",
      "Epoch 616/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3948 - acc: 0.8150 - val_loss: 0.4093 - val_acc: 0.8250\n",
      "Epoch 617/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3949 - acc: 0.8150 - val_loss: 0.4096 - val_acc: 0.8263\n",
      "Epoch 618/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3955 - acc: 0.8150 - val_loss: 0.4088 - val_acc: 0.8250\n",
      "Epoch 619/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3948 - acc: 0.8150 - val_loss: 0.4109 - val_acc: 0.8250\n",
      "Epoch 620/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3939 - acc: 0.8150 - val_loss: 0.4139 - val_acc: 0.8250\n",
      "Epoch 621/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3944 - acc: 0.8250 - val_loss: 0.4175 - val_acc: 0.8225\n",
      "Epoch 622/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3963 - acc: 0.8250 - val_loss: 0.4181 - val_acc: 0.8213\n",
      "Epoch 623/1000\n",
      "200/200 [==============================] - 0s 162us/step - loss: 0.3961 - acc: 0.8300 - val_loss: 0.4168 - val_acc: 0.8213\n",
      "Epoch 624/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3953 - acc: 0.8250 - val_loss: 0.4128 - val_acc: 0.8237\n",
      "Epoch 625/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3948 - acc: 0.8250 - val_loss: 0.4117 - val_acc: 0.8263\n",
      "Epoch 626/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3952 - acc: 0.8150 - val_loss: 0.4097 - val_acc: 0.8237\n",
      "Epoch 627/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3944 - acc: 0.8150 - val_loss: 0.4098 - val_acc: 0.8250\n",
      "Epoch 628/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3950 - acc: 0.8150 - val_loss: 0.4096 - val_acc: 0.8225\n",
      "Epoch 629/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3943 - acc: 0.8150 - val_loss: 0.4122 - val_acc: 0.8250\n",
      "Epoch 630/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3947 - acc: 0.8200 - val_loss: 0.4126 - val_acc: 0.8275\n",
      "Epoch 631/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3947 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8287\n",
      "Epoch 632/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3948 - acc: 0.8250 - val_loss: 0.4126 - val_acc: 0.8263\n",
      "Epoch 633/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3943 - acc: 0.8200 - val_loss: 0.4117 - val_acc: 0.8250\n",
      "Epoch 634/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3950 - acc: 0.8200 - val_loss: 0.4123 - val_acc: 0.8213\n",
      "Epoch 635/1000\n",
      "200/200 [==============================] - 0s 160us/step - loss: 0.3951 - acc: 0.8200 - val_loss: 0.4105 - val_acc: 0.8225\n",
      "Epoch 636/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3947 - acc: 0.8150 - val_loss: 0.4124 - val_acc: 0.8225\n",
      "Epoch 637/1000\n",
      "200/200 [==============================] - 0s 161us/step - loss: 0.3944 - acc: 0.8250 - val_loss: 0.4146 - val_acc: 0.8250\n",
      "Epoch 638/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3941 - acc: 0.8250 - val_loss: 0.4127 - val_acc: 0.8275\n",
      "Epoch 639/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3935 - acc: 0.8250 - val_loss: 0.4095 - val_acc: 0.8237\n",
      "Epoch 640/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.3946 - acc: 0.8150 - val_loss: 0.4076 - val_acc: 0.8275\n",
      "Epoch 641/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3945 - acc: 0.8100 - val_loss: 0.4084 - val_acc: 0.8250\n",
      "Epoch 642/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3942 - acc: 0.8200 - val_loss: 0.4109 - val_acc: 0.8237\n",
      "Epoch 643/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3942 - acc: 0.8250 - val_loss: 0.4127 - val_acc: 0.8263\n",
      "Epoch 644/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3950 - acc: 0.8250 - val_loss: 0.4154 - val_acc: 0.8237\n",
      "Epoch 645/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3946 - acc: 0.8250 - val_loss: 0.4149 - val_acc: 0.8275\n",
      "Epoch 646/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3951 - acc: 0.8250 - val_loss: 0.4159 - val_acc: 0.8250\n",
      "Epoch 647/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3949 - acc: 0.8250 - val_loss: 0.4115 - val_acc: 0.8213\n",
      "Epoch 648/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3938 - acc: 0.8200 - val_loss: 0.4109 - val_acc: 0.8225\n",
      "Epoch 649/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3945 - acc: 0.8200 - val_loss: 0.4110 - val_acc: 0.8225\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 129us/step - loss: 0.3940 - acc: 0.8150 - val_loss: 0.4112 - val_acc: 0.8263\n",
      "Epoch 651/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3943 - acc: 0.8200 - val_loss: 0.4130 - val_acc: 0.8263\n",
      "Epoch 652/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3949 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8237\n",
      "Epoch 653/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3948 - acc: 0.8200 - val_loss: 0.4131 - val_acc: 0.8263\n",
      "Epoch 654/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3932 - acc: 0.8150 - val_loss: 0.4112 - val_acc: 0.8225\n",
      "Epoch 655/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3966 - acc: 0.8200 - val_loss: 0.4106 - val_acc: 0.8263\n",
      "Epoch 656/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3941 - acc: 0.8200 - val_loss: 0.4102 - val_acc: 0.8225\n",
      "Epoch 657/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3936 - acc: 0.8200 - val_loss: 0.4117 - val_acc: 0.8225\n",
      "Epoch 658/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3939 - acc: 0.8200 - val_loss: 0.4123 - val_acc: 0.8263\n",
      "Epoch 659/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3957 - acc: 0.8250 - val_loss: 0.4148 - val_acc: 0.8225\n",
      "Epoch 660/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3953 - acc: 0.8250 - val_loss: 0.4161 - val_acc: 0.8225\n",
      "Epoch 661/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.3951 - acc: 0.8250 - val_loss: 0.4131 - val_acc: 0.8263\n",
      "Epoch 662/1000\n",
      "200/200 [==============================] - 0s 154us/step - loss: 0.3943 - acc: 0.8200 - val_loss: 0.4121 - val_acc: 0.8263\n",
      "Epoch 663/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3934 - acc: 0.8200 - val_loss: 0.4121 - val_acc: 0.8263\n",
      "Epoch 664/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3938 - acc: 0.8200 - val_loss: 0.4108 - val_acc: 0.8225\n",
      "Epoch 665/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3935 - acc: 0.8200 - val_loss: 0.4111 - val_acc: 0.8250\n",
      "Epoch 666/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3933 - acc: 0.8250 - val_loss: 0.4147 - val_acc: 0.8200\n",
      "Epoch 667/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3945 - acc: 0.8250 - val_loss: 0.4162 - val_acc: 0.8200\n",
      "Epoch 668/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3949 - acc: 0.8250 - val_loss: 0.4159 - val_acc: 0.8200\n",
      "Epoch 669/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3947 - acc: 0.8250 - val_loss: 0.4128 - val_acc: 0.8250\n",
      "Epoch 670/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4098 - val_acc: 0.8225\n",
      "Epoch 671/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3942 - acc: 0.8150 - val_loss: 0.4098 - val_acc: 0.8287\n",
      "Epoch 672/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.3934 - acc: 0.8150 - val_loss: 0.4104 - val_acc: 0.8250\n",
      "Epoch 673/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3939 - acc: 0.8150 - val_loss: 0.4116 - val_acc: 0.8250\n",
      "Epoch 674/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3948 - acc: 0.8150 - val_loss: 0.4111 - val_acc: 0.8250\n",
      "Epoch 675/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3959 - acc: 0.8200 - val_loss: 0.4113 - val_acc: 0.8250\n",
      "Epoch 676/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3945 - acc: 0.8200 - val_loss: 0.4118 - val_acc: 0.8263\n",
      "Epoch 677/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3934 - acc: 0.8200 - val_loss: 0.4137 - val_acc: 0.8287\n",
      "Epoch 678/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3947 - acc: 0.8250 - val_loss: 0.4181 - val_acc: 0.8237\n",
      "Epoch 679/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3941 - acc: 0.8250 - val_loss: 0.4167 - val_acc: 0.8263\n",
      "Epoch 680/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5220 - acc: 0.750 - 0s 105us/step - loss: 0.3937 - acc: 0.8250 - val_loss: 0.4117 - val_acc: 0.8237\n",
      "Epoch 681/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3932 - acc: 0.8150 - val_loss: 0.4090 - val_acc: 0.8250\n",
      "Epoch 682/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3938 - acc: 0.8100 - val_loss: 0.4087 - val_acc: 0.8263\n",
      "Epoch 683/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3941 - acc: 0.8100 - val_loss: 0.4096 - val_acc: 0.8263\n",
      "Epoch 684/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3935 - acc: 0.8150 - val_loss: 0.4103 - val_acc: 0.8250\n",
      "Epoch 685/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3934 - acc: 0.8150 - val_loss: 0.4115 - val_acc: 0.8237\n",
      "Epoch 686/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3931 - acc: 0.8150 - val_loss: 0.4108 - val_acc: 0.8237\n",
      "Epoch 687/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3936 - acc: 0.8150 - val_loss: 0.4098 - val_acc: 0.8250\n",
      "Epoch 688/1000\n",
      "200/200 [==============================] - 0s 177us/step - loss: 0.3935 - acc: 0.8150 - val_loss: 0.4102 - val_acc: 0.8250\n",
      "Epoch 689/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3933 - acc: 0.8150 - val_loss: 0.4109 - val_acc: 0.8250\n",
      "Epoch 690/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3935 - acc: 0.8200 - val_loss: 0.4127 - val_acc: 0.8263\n",
      "Epoch 691/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3936 - acc: 0.8200 - val_loss: 0.4134 - val_acc: 0.8263\n",
      "Epoch 692/1000\n",
      "200/200 [==============================] - 0s 186us/step - loss: 0.3950 - acc: 0.8250 - val_loss: 0.4205 - val_acc: 0.8225\n",
      "Epoch 693/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3947 - acc: 0.8250 - val_loss: 0.4174 - val_acc: 0.8250\n",
      "Epoch 694/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3944 - acc: 0.8250 - val_loss: 0.4126 - val_acc: 0.8250\n",
      "Epoch 695/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3934 - acc: 0.8150 - val_loss: 0.4101 - val_acc: 0.8275\n",
      "Epoch 696/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3941 - acc: 0.8150 - val_loss: 0.4102 - val_acc: 0.8263\n",
      "Epoch 697/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3930 - acc: 0.8150 - val_loss: 0.4117 - val_acc: 0.8275\n",
      "Epoch 698/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3928 - acc: 0.8150 - val_loss: 0.4143 - val_acc: 0.8250\n",
      "Epoch 699/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3932 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8250\n",
      "Epoch 700/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3932 - acc: 0.8200 - val_loss: 0.4148 - val_acc: 0.8237\n",
      "Epoch 701/1000\n",
      "200/200 [==============================] - 0s 172us/step - loss: 0.3928 - acc: 0.8200 - val_loss: 0.4120 - val_acc: 0.8237\n",
      "Epoch 702/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3928 - acc: 0.8150 - val_loss: 0.4105 - val_acc: 0.8225\n",
      "Epoch 703/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.3940 - acc: 0.8150 - val_loss: 0.4112 - val_acc: 0.8225\n",
      "Epoch 704/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3938 - acc: 0.8150 - val_loss: 0.4104 - val_acc: 0.8237\n",
      "Epoch 705/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3931 - acc: 0.8150 - val_loss: 0.4115 - val_acc: 0.8237\n",
      "Epoch 706/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3930 - acc: 0.8200 - val_loss: 0.4123 - val_acc: 0.8263\n",
      "Epoch 707/1000\n",
      "200/200 [==============================] - 0s 154us/step - loss: 0.3936 - acc: 0.8200 - val_loss: 0.4125 - val_acc: 0.8263\n",
      "Epoch 708/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.3928 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8275\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 126us/step - loss: 0.3931 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8275\n",
      "Epoch 710/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.3933 - acc: 0.8200 - val_loss: 0.4162 - val_acc: 0.8250\n",
      "Epoch 711/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3928 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8275\n",
      "Epoch 712/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3935 - acc: 0.8200 - val_loss: 0.4167 - val_acc: 0.8250\n",
      "Epoch 713/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4156 - val_acc: 0.8237\n",
      "Epoch 714/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3928 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8225\n",
      "Epoch 715/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4148 - val_acc: 0.8225\n",
      "Epoch 716/1000\n",
      "200/200 [==============================] - 0s 174us/step - loss: 0.3948 - acc: 0.8200 - val_loss: 0.4132 - val_acc: 0.8250\n",
      "Epoch 717/1000\n",
      "200/200 [==============================] - 0s 164us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8275\n",
      "Epoch 718/1000\n",
      "200/200 [==============================] - 0s 186us/step - loss: 0.3925 - acc: 0.8200 - val_loss: 0.4141 - val_acc: 0.8250\n",
      "Epoch 719/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3927 - acc: 0.8200 - val_loss: 0.4148 - val_acc: 0.8237\n",
      "Epoch 720/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3923 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8275\n",
      "Epoch 721/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3924 - acc: 0.8200 - val_loss: 0.4159 - val_acc: 0.8263\n",
      "Epoch 722/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3927 - acc: 0.8250 - val_loss: 0.4168 - val_acc: 0.8250\n",
      "Epoch 723/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3923 - acc: 0.8250 - val_loss: 0.4152 - val_acc: 0.8237\n",
      "Epoch 724/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3938 - acc: 0.8150 - val_loss: 0.4116 - val_acc: 0.8250\n",
      "Epoch 725/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3930 - acc: 0.8150 - val_loss: 0.4126 - val_acc: 0.8237\n",
      "Epoch 726/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3930 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8263\n",
      "Epoch 727/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4131 - val_acc: 0.8275\n",
      "Epoch 728/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3924 - acc: 0.8150 - val_loss: 0.4122 - val_acc: 0.8287\n",
      "Epoch 729/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3935 - acc: 0.8200 - val_loss: 0.4163 - val_acc: 0.8200\n",
      "Epoch 730/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3936 - acc: 0.8150 - val_loss: 0.4150 - val_acc: 0.8225\n",
      "Epoch 731/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3938 - acc: 0.8150 - val_loss: 0.4140 - val_acc: 0.8237\n",
      "Epoch 732/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3936 - acc: 0.8200 - val_loss: 0.4141 - val_acc: 0.8213\n",
      "Epoch 733/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3935 - acc: 0.8150 - val_loss: 0.4113 - val_acc: 0.8237\n",
      "Epoch 734/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3927 - acc: 0.8150 - val_loss: 0.4121 - val_acc: 0.8237\n",
      "Epoch 735/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3928 - acc: 0.8150 - val_loss: 0.4129 - val_acc: 0.8237\n",
      "Epoch 736/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3935 - acc: 0.8150 - val_loss: 0.4132 - val_acc: 0.8250\n",
      "Epoch 737/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3933 - acc: 0.8200 - val_loss: 0.4155 - val_acc: 0.8275\n",
      "Epoch 738/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3935 - acc: 0.8200 - val_loss: 0.4167 - val_acc: 0.8225\n",
      "Epoch 739/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8250\n",
      "Epoch 740/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4155 - val_acc: 0.8275\n",
      "Epoch 741/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3922 - acc: 0.8200 - val_loss: 0.4165 - val_acc: 0.8237\n",
      "Epoch 742/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3928 - acc: 0.8150 - val_loss: 0.4147 - val_acc: 0.8237\n",
      "Epoch 743/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.3924 - acc: 0.8150 - val_loss: 0.4158 - val_acc: 0.8225\n",
      "Epoch 744/1000\n",
      "200/200 [==============================] - 0s 163us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4156 - val_acc: 0.8237\n",
      "Epoch 745/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3927 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8213\n",
      "Epoch 746/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3932 - acc: 0.8150 - val_loss: 0.4138 - val_acc: 0.8213\n",
      "Epoch 747/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3925 - acc: 0.8150 - val_loss: 0.4141 - val_acc: 0.8237\n",
      "Epoch 748/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3941 - acc: 0.8150 - val_loss: 0.4122 - val_acc: 0.8225\n",
      "Epoch 749/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3923 - acc: 0.8200 - val_loss: 0.4146 - val_acc: 0.8263\n",
      "Epoch 750/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.3924 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8275\n",
      "Epoch 751/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3918 - acc: 0.8250 - val_loss: 0.4163 - val_acc: 0.8275\n",
      "Epoch 752/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3921 - acc: 0.8250 - val_loss: 0.4172 - val_acc: 0.8263\n",
      "Epoch 753/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3925 - acc: 0.8250 - val_loss: 0.4154 - val_acc: 0.8275\n",
      "Epoch 754/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4136 - val_acc: 0.8237\n",
      "Epoch 755/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4108 - val_acc: 0.8225\n",
      "Epoch 756/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3932 - acc: 0.8100 - val_loss: 0.4106 - val_acc: 0.8225\n",
      "Epoch 757/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3930 - acc: 0.8100 - val_loss: 0.4112 - val_acc: 0.8237\n",
      "Epoch 758/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3923 - acc: 0.8200 - val_loss: 0.4138 - val_acc: 0.8213\n",
      "Epoch 759/1000\n",
      "200/200 [==============================] - 0s 180us/step - loss: 0.3916 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8213\n",
      "Epoch 760/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4145 - val_acc: 0.8237\n",
      "Epoch 761/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.3922 - acc: 0.8200 - val_loss: 0.4164 - val_acc: 0.8213\n",
      "Epoch 762/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8213\n",
      "Epoch 763/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3922 - acc: 0.8150 - val_loss: 0.4151 - val_acc: 0.8237\n",
      "Epoch 764/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3917 - acc: 0.8150 - val_loss: 0.4157 - val_acc: 0.8237\n",
      "Epoch 765/1000\n",
      "200/200 [==============================] - 0s 161us/step - loss: 0.3916 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8263\n",
      "Epoch 766/1000\n",
      "200/200 [==============================] - 0s 155us/step - loss: 0.3917 - acc: 0.8200 - val_loss: 0.4145 - val_acc: 0.8250\n",
      "Epoch 767/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3928 - acc: 0.8150 - val_loss: 0.4145 - val_acc: 0.8250\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 130us/step - loss: 0.3926 - acc: 0.8150 - val_loss: 0.4118 - val_acc: 0.8237\n",
      "Epoch 769/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3918 - acc: 0.8150 - val_loss: 0.4125 - val_acc: 0.8225\n",
      "Epoch 770/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3927 - acc: 0.8150 - val_loss: 0.4147 - val_acc: 0.8263\n",
      "Epoch 771/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3916 - acc: 0.8250 - val_loss: 0.4139 - val_acc: 0.8250\n",
      "Epoch 772/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3915 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8225\n",
      "Epoch 773/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4161 - val_acc: 0.8213\n",
      "Epoch 774/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2219 - acc: 0.968 - 0s 133us/step - loss: 0.3915 - acc: 0.8200 - val_loss: 0.4133 - val_acc: 0.8237\n",
      "Epoch 775/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4133 - val_acc: 0.8250\n",
      "Epoch 776/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8237\n",
      "Epoch 777/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3915 - acc: 0.8200 - val_loss: 0.4136 - val_acc: 0.8237\n",
      "Epoch 778/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4134 - val_acc: 0.8250\n",
      "Epoch 779/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8237\n",
      "Epoch 780/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8237\n",
      "Epoch 781/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3917 - acc: 0.8250 - val_loss: 0.4138 - val_acc: 0.8250\n",
      "Epoch 782/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4121 - val_acc: 0.8225\n",
      "Epoch 783/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4141 - val_acc: 0.8250\n",
      "Epoch 784/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3932 - acc: 0.8200 - val_loss: 0.4123 - val_acc: 0.8237\n",
      "Epoch 785/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8237\n",
      "Epoch 786/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3913 - acc: 0.8200 - val_loss: 0.4137 - val_acc: 0.8250\n",
      "Epoch 787/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8225\n",
      "Epoch 788/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8213\n",
      "Epoch 789/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4137 - val_acc: 0.8237\n",
      "Epoch 790/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4139 - val_acc: 0.8237\n",
      "Epoch 791/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3931 - acc: 0.8200 - val_loss: 0.4127 - val_acc: 0.8237\n",
      "Epoch 792/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8250\n",
      "Epoch 793/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3914 - acc: 0.8200 - val_loss: 0.4175 - val_acc: 0.8225\n",
      "Epoch 794/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3917 - acc: 0.8200 - val_loss: 0.4178 - val_acc: 0.8213\n",
      "Epoch 795/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.3932 - acc: 0.8250 - val_loss: 0.4197 - val_acc: 0.8213\n",
      "Epoch 796/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3930 - acc: 0.8250 - val_loss: 0.4192 - val_acc: 0.8200\n",
      "Epoch 797/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3928 - acc: 0.8200 - val_loss: 0.4172 - val_acc: 0.8263\n",
      "Epoch 798/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3929 - acc: 0.8250 - val_loss: 0.4195 - val_acc: 0.8225\n",
      "Epoch 799/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.3917 - acc: 0.8250 - val_loss: 0.4149 - val_acc: 0.8237\n",
      "Epoch 800/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3925 - acc: 0.8200 - val_loss: 0.4131 - val_acc: 0.8250\n",
      "Epoch 801/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4130 - val_acc: 0.8225\n",
      "Epoch 802/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3913 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8225\n",
      "Epoch 803/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3919 - acc: 0.8150 - val_loss: 0.4139 - val_acc: 0.8213\n",
      "Epoch 804/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3920 - acc: 0.8150 - val_loss: 0.4124 - val_acc: 0.8225\n",
      "Epoch 805/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3922 - acc: 0.8150 - val_loss: 0.4128 - val_acc: 0.8237\n",
      "Epoch 806/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.3908 - acc: 0.8150 - val_loss: 0.4154 - val_acc: 0.8213\n",
      "Epoch 807/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3912 - acc: 0.8200 - val_loss: 0.4159 - val_acc: 0.8213\n",
      "Epoch 808/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3912 - acc: 0.8150 - val_loss: 0.4155 - val_acc: 0.8225\n",
      "Epoch 809/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3913 - acc: 0.8250 - val_loss: 0.4186 - val_acc: 0.8225\n",
      "Epoch 810/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3916 - acc: 0.8250 - val_loss: 0.4198 - val_acc: 0.8237\n",
      "Epoch 811/1000\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.3917 - acc: 0.8250 - val_loss: 0.4171 - val_acc: 0.8237\n",
      "Epoch 812/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3914 - acc: 0.8250 - val_loss: 0.4146 - val_acc: 0.8237\n",
      "Epoch 813/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4152 - val_acc: 0.8275\n",
      "Epoch 814/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.3913 - acc: 0.8200 - val_loss: 0.4141 - val_acc: 0.8237\n",
      "Epoch 815/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3912 - acc: 0.8200 - val_loss: 0.4161 - val_acc: 0.8287\n",
      "Epoch 816/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3917 - acc: 0.8250 - val_loss: 0.4188 - val_acc: 0.8250\n",
      "Epoch 817/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3916 - acc: 0.8250 - val_loss: 0.4191 - val_acc: 0.8225\n",
      "Epoch 818/1000\n",
      "200/200 [==============================] - 0s 163us/step - loss: 0.3911 - acc: 0.8250 - val_loss: 0.4151 - val_acc: 0.8250\n",
      "Epoch 819/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3912 - acc: 0.8200 - val_loss: 0.4145 - val_acc: 0.8250\n",
      "Epoch 820/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3929 - acc: 0.8250 - val_loss: 0.4167 - val_acc: 0.8250\n",
      "Epoch 821/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3902 - acc: 0.8250 - val_loss: 0.4136 - val_acc: 0.8237\n",
      "Epoch 822/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3912 - acc: 0.8150 - val_loss: 0.4136 - val_acc: 0.8237\n",
      "Epoch 823/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3914 - acc: 0.8150 - val_loss: 0.4138 - val_acc: 0.8250\n",
      "Epoch 824/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3909 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8237\n",
      "Epoch 825/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4161 - val_acc: 0.8250\n",
      "Epoch 826/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.3913 - acc: 0.8200 - val_loss: 0.4168 - val_acc: 0.8263\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 118us/step - loss: 0.3912 - acc: 0.8250 - val_loss: 0.4163 - val_acc: 0.8275\n",
      "Epoch 828/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3906 - acc: 0.8250 - val_loss: 0.4154 - val_acc: 0.8250\n",
      "Epoch 829/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3905 - acc: 0.8200 - val_loss: 0.4139 - val_acc: 0.8237\n",
      "Epoch 830/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3924 - acc: 0.8200 - val_loss: 0.4163 - val_acc: 0.8237\n",
      "Epoch 831/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3920 - acc: 0.8200 - val_loss: 0.4140 - val_acc: 0.8213\n",
      "Epoch 832/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3921 - acc: 0.8150 - val_loss: 0.4139 - val_acc: 0.8213\n",
      "Epoch 833/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3927 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8213\n",
      "Epoch 834/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4156 - val_acc: 0.8250\n",
      "Epoch 835/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3913 - acc: 0.8200 - val_loss: 0.4134 - val_acc: 0.8225\n",
      "Epoch 836/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3906 - acc: 0.8200 - val_loss: 0.4135 - val_acc: 0.8225\n",
      "Epoch 837/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3912 - acc: 0.8200 - val_loss: 0.4140 - val_acc: 0.8250\n",
      "Epoch 838/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4156 - val_acc: 0.8237\n",
      "Epoch 839/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8275\n",
      "Epoch 840/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3904 - acc: 0.8200 - val_loss: 0.4183 - val_acc: 0.8275\n",
      "Epoch 841/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3907 - acc: 0.8200 - val_loss: 0.4168 - val_acc: 0.8250\n",
      "Epoch 842/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.3907 - acc: 0.8200 - val_loss: 0.4169 - val_acc: 0.8225\n",
      "Epoch 843/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3921 - acc: 0.8150 - val_loss: 0.4177 - val_acc: 0.8237\n",
      "Epoch 844/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3927 - acc: 0.8200 - val_loss: 0.4184 - val_acc: 0.8213\n",
      "Epoch 845/1000\n",
      "200/200 [==============================] - 0s 121us/step - loss: 0.3921 - acc: 0.8250 - val_loss: 0.4202 - val_acc: 0.8213\n",
      "Epoch 846/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.3909 - acc: 0.8250 - val_loss: 0.4206 - val_acc: 0.8225\n",
      "Epoch 847/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3906 - acc: 0.8200 - val_loss: 0.4191 - val_acc: 0.8250\n",
      "Epoch 848/1000\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4171 - val_acc: 0.8250\n",
      "Epoch 849/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3902 - acc: 0.8200 - val_loss: 0.4165 - val_acc: 0.8225\n",
      "Epoch 850/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3905 - acc: 0.8200 - val_loss: 0.4170 - val_acc: 0.8225\n",
      "Epoch 851/1000\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4191 - val_acc: 0.8225\n",
      "Epoch 852/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4170 - val_acc: 0.8225\n",
      "Epoch 853/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3281 - acc: 0.875 - 0s 105us/step - loss: 0.3916 - acc: 0.8200 - val_loss: 0.4178 - val_acc: 0.8213\n",
      "Epoch 854/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3913 - acc: 0.8150 - val_loss: 0.4181 - val_acc: 0.8200\n",
      "Epoch 855/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3919 - acc: 0.8150 - val_loss: 0.4181 - val_acc: 0.8200\n",
      "Epoch 856/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3917 - acc: 0.8200 - val_loss: 0.4187 - val_acc: 0.8187\n",
      "Epoch 857/1000\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.3910 - acc: 0.8200 - val_loss: 0.4188 - val_acc: 0.8237\n",
      "Epoch 858/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3906 - acc: 0.8250 - val_loss: 0.4214 - val_acc: 0.8213\n",
      "Epoch 859/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3916 - acc: 0.8250 - val_loss: 0.4195 - val_acc: 0.8200\n",
      "Epoch 860/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3917 - acc: 0.8300 - val_loss: 0.4200 - val_acc: 0.8187\n",
      "Epoch 861/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3917 - acc: 0.8300 - val_loss: 0.4206 - val_acc: 0.8200\n",
      "Epoch 862/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3910 - acc: 0.8250 - val_loss: 0.4180 - val_acc: 0.8250\n",
      "Epoch 863/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3904 - acc: 0.8250 - val_loss: 0.4162 - val_acc: 0.8213\n",
      "Epoch 864/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3905 - acc: 0.8200 - val_loss: 0.4171 - val_acc: 0.8237\n",
      "Epoch 865/1000\n",
      "200/200 [==============================] - 0s 125us/step - loss: 0.3903 - acc: 0.8200 - val_loss: 0.4186 - val_acc: 0.8225\n",
      "Epoch 866/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.3921 - acc: 0.8200 - val_loss: 0.4218 - val_acc: 0.8250\n",
      "Epoch 867/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3908 - acc: 0.8250 - val_loss: 0.4213 - val_acc: 0.8237\n",
      "Epoch 868/1000\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.3917 - acc: 0.8250 - val_loss: 0.4232 - val_acc: 0.8237\n",
      "Epoch 869/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3920 - acc: 0.8250 - val_loss: 0.4196 - val_acc: 0.8213\n",
      "Epoch 870/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3916 - acc: 0.8200 - val_loss: 0.4191 - val_acc: 0.8213\n",
      "Epoch 871/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3913 - acc: 0.8200 - val_loss: 0.4180 - val_acc: 0.8213\n",
      "Epoch 872/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8263\n",
      "Epoch 873/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3903 - acc: 0.8200 - val_loss: 0.4181 - val_acc: 0.8237\n",
      "Epoch 874/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3902 - acc: 0.8250 - val_loss: 0.4174 - val_acc: 0.8213\n",
      "Epoch 875/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3899 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8225\n",
      "Epoch 876/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3922 - acc: 0.8150 - val_loss: 0.4141 - val_acc: 0.8213\n",
      "Epoch 877/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3907 - acc: 0.8150 - val_loss: 0.4155 - val_acc: 0.8237\n",
      "Epoch 878/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3912 - acc: 0.8150 - val_loss: 0.4139 - val_acc: 0.8225\n",
      "Epoch 879/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3902 - acc: 0.8150 - val_loss: 0.4146 - val_acc: 0.8200\n",
      "Epoch 880/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3635 - acc: 0.812 - 0s 140us/step - loss: 0.3912 - acc: 0.8150 - val_loss: 0.4157 - val_acc: 0.8237\n",
      "Epoch 881/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3906 - acc: 0.8250 - val_loss: 0.4178 - val_acc: 0.8263\n",
      "Epoch 882/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3905 - acc: 0.8200 - val_loss: 0.4168 - val_acc: 0.8237\n",
      "Epoch 883/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3903 - acc: 0.8200 - val_loss: 0.4186 - val_acc: 0.8213\n",
      "Epoch 884/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3903 - acc: 0.8200 - val_loss: 0.4176 - val_acc: 0.8237\n",
      "Epoch 885/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3906 - acc: 0.8200 - val_loss: 0.4171 - val_acc: 0.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3900 - acc: 0.8200 - val_loss: 0.4167 - val_acc: 0.8225\n",
      "Epoch 887/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3901 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8213\n",
      "Epoch 888/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3911 - acc: 0.8200 - val_loss: 0.4151 - val_acc: 0.8250\n",
      "Epoch 889/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3900 - acc: 0.8250 - val_loss: 0.4180 - val_acc: 0.8275\n",
      "Epoch 890/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3497 - acc: 0.843 - 0s 137us/step - loss: 0.3906 - acc: 0.8250 - val_loss: 0.4192 - val_acc: 0.8250\n",
      "Epoch 891/1000\n",
      "200/200 [==============================] - 0s 146us/step - loss: 0.3904 - acc: 0.8250 - val_loss: 0.4178 - val_acc: 0.8263\n",
      "Epoch 892/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3899 - acc: 0.8200 - val_loss: 0.4168 - val_acc: 0.8225\n",
      "Epoch 893/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3905 - acc: 0.8200 - val_loss: 0.4176 - val_acc: 0.8213\n",
      "Epoch 894/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3915 - acc: 0.8200 - val_loss: 0.4179 - val_acc: 0.8213\n",
      "Epoch 895/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3909 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8263\n",
      "Epoch 896/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3904 - acc: 0.8200 - val_loss: 0.4173 - val_acc: 0.8187\n",
      "Epoch 897/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3906 - acc: 0.8200 - val_loss: 0.4168 - val_acc: 0.8213\n",
      "Epoch 898/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3901 - acc: 0.8200 - val_loss: 0.4167 - val_acc: 0.8225\n",
      "Epoch 899/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3892 - acc: 0.8250 - val_loss: 0.4151 - val_acc: 0.8187\n",
      "Epoch 900/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3902 - acc: 0.8200 - val_loss: 0.4142 - val_acc: 0.8225\n",
      "Epoch 901/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3912 - acc: 0.8150 - val_loss: 0.4140 - val_acc: 0.8237\n",
      "Epoch 902/1000\n",
      "200/200 [==============================] - 0s 116us/step - loss: 0.3911 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8237\n",
      "Epoch 903/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3912 - acc: 0.8150 - val_loss: 0.4147 - val_acc: 0.8225\n",
      "Epoch 904/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3907 - acc: 0.8200 - val_loss: 0.4157 - val_acc: 0.8200\n",
      "Epoch 905/1000\n",
      "200/200 [==============================] - 0s 166us/step - loss: 0.3895 - acc: 0.8150 - val_loss: 0.4155 - val_acc: 0.8213\n",
      "Epoch 906/1000\n",
      "200/200 [==============================] - 0s 148us/step - loss: 0.3904 - acc: 0.8200 - val_loss: 0.4164 - val_acc: 0.8275\n",
      "Epoch 907/1000\n",
      "200/200 [==============================] - 0s 133us/step - loss: 0.3898 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8225\n",
      "Epoch 908/1000\n",
      "200/200 [==============================] - 0s 126us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4182 - val_acc: 0.8225\n",
      "Epoch 909/1000\n",
      "200/200 [==============================] - 0s 147us/step - loss: 0.3902 - acc: 0.8200 - val_loss: 0.4184 - val_acc: 0.8187\n",
      "Epoch 910/1000\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.3899 - acc: 0.8200 - val_loss: 0.4149 - val_acc: 0.8187\n",
      "Epoch 911/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3897 - acc: 0.8150 - val_loss: 0.4142 - val_acc: 0.8187\n",
      "Epoch 912/1000\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.3906 - acc: 0.8150 - val_loss: 0.4155 - val_acc: 0.8225\n",
      "Epoch 913/1000\n",
      "200/200 [==============================] - 0s 158us/step - loss: 0.3894 - acc: 0.8250 - val_loss: 0.4164 - val_acc: 0.8237\n",
      "Epoch 914/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3895 - acc: 0.8250 - val_loss: 0.4172 - val_acc: 0.8213\n",
      "Epoch 915/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3906 - acc: 0.8250 - val_loss: 0.4187 - val_acc: 0.8213\n",
      "Epoch 916/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4230 - val_acc: 0.8225\n",
      "Epoch 917/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3910 - acc: 0.8250 - val_loss: 0.4228 - val_acc: 0.8213\n",
      "Epoch 918/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3911 - acc: 0.8250 - val_loss: 0.4203 - val_acc: 0.8237\n",
      "Epoch 919/1000\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.3908 - acc: 0.8250 - val_loss: 0.4162 - val_acc: 0.8250\n",
      "Epoch 920/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3911 - acc: 0.8250 - val_loss: 0.4215 - val_acc: 0.8250\n",
      "Epoch 921/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3909 - acc: 0.8250 - val_loss: 0.4233 - val_acc: 0.8225\n",
      "Epoch 922/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3153 - acc: 0.875 - 0s 124us/step - loss: 0.3912 - acc: 0.8300 - val_loss: 0.4225 - val_acc: 0.8225\n",
      "Epoch 923/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3907 - acc: 0.8250 - val_loss: 0.4213 - val_acc: 0.8213\n",
      "Epoch 924/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3893 - acc: 0.8300 - val_loss: 0.4192 - val_acc: 0.8213\n",
      "Epoch 925/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3897 - acc: 0.8200 - val_loss: 0.4182 - val_acc: 0.8187\n",
      "Epoch 926/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3902 - acc: 0.8250 - val_loss: 0.4167 - val_acc: 0.8213\n",
      "Epoch 927/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4185 - val_acc: 0.8213\n",
      "Epoch 928/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3901 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8225\n",
      "Epoch 929/1000\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.3897 - acc: 0.8200 - val_loss: 0.4178 - val_acc: 0.8225\n",
      "Epoch 930/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3902 - acc: 0.8150 - val_loss: 0.4153 - val_acc: 0.8237\n",
      "Epoch 931/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3905 - acc: 0.8150 - val_loss: 0.4157 - val_acc: 0.8213\n",
      "Epoch 932/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3897 - acc: 0.8200 - val_loss: 0.4163 - val_acc: 0.8187\n",
      "Epoch 933/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3897 - acc: 0.8150 - val_loss: 0.4183 - val_acc: 0.8213\n",
      "Epoch 934/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3895 - acc: 0.8250 - val_loss: 0.4188 - val_acc: 0.8237\n",
      "Epoch 935/1000\n",
      "200/200 [==============================] - 0s 135us/step - loss: 0.3893 - acc: 0.8250 - val_loss: 0.4186 - val_acc: 0.8263\n",
      "Epoch 936/1000\n",
      "200/200 [==============================] - 0s 154us/step - loss: 0.3895 - acc: 0.8250 - val_loss: 0.4184 - val_acc: 0.8237\n",
      "Epoch 937/1000\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.3895 - acc: 0.8200 - val_loss: 0.4171 - val_acc: 0.8263\n",
      "Epoch 938/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3895 - acc: 0.8200 - val_loss: 0.4187 - val_acc: 0.8237\n",
      "Epoch 939/1000\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3416 - acc: 0.843 - 0s 128us/step - loss: 0.3893 - acc: 0.8250 - val_loss: 0.4182 - val_acc: 0.8263\n",
      "Epoch 940/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3891 - acc: 0.8200 - val_loss: 0.4180 - val_acc: 0.8263\n",
      "Epoch 941/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3894 - acc: 0.8200 - val_loss: 0.4185 - val_acc: 0.8225\n",
      "Epoch 942/1000\n",
      "200/200 [==============================] - 0s 144us/step - loss: 0.3899 - acc: 0.8250 - val_loss: 0.4206 - val_acc: 0.8225\n",
      "Epoch 943/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3894 - acc: 0.8250 - val_loss: 0.4184 - val_acc: 0.8237\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 103us/step - loss: 0.3893 - acc: 0.8250 - val_loss: 0.4172 - val_acc: 0.8225\n",
      "Epoch 945/1000\n",
      "200/200 [==============================] - 0s 173us/step - loss: 0.3889 - acc: 0.8200 - val_loss: 0.4166 - val_acc: 0.8225\n",
      "Epoch 946/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3891 - acc: 0.8200 - val_loss: 0.4154 - val_acc: 0.8225\n",
      "Epoch 947/1000\n",
      "200/200 [==============================] - 0s 172us/step - loss: 0.3892 - acc: 0.8200 - val_loss: 0.4147 - val_acc: 0.8237\n",
      "Epoch 948/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3904 - acc: 0.8200 - val_loss: 0.4134 - val_acc: 0.8225\n",
      "Epoch 949/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3908 - acc: 0.8150 - val_loss: 0.4144 - val_acc: 0.8213\n",
      "Epoch 950/1000\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.3895 - acc: 0.8150 - val_loss: 0.4154 - val_acc: 0.8187\n",
      "Epoch 951/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3897 - acc: 0.8150 - val_loss: 0.4153 - val_acc: 0.8187\n",
      "Epoch 952/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3893 - acc: 0.8150 - val_loss: 0.4158 - val_acc: 0.8200\n",
      "Epoch 953/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3895 - acc: 0.8150 - val_loss: 0.4170 - val_acc: 0.8237\n",
      "Epoch 954/1000\n",
      "200/200 [==============================] - 0s 136us/step - loss: 0.3891 - acc: 0.8200 - val_loss: 0.4169 - val_acc: 0.8213\n",
      "Epoch 955/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3892 - acc: 0.8200 - val_loss: 0.4186 - val_acc: 0.8275\n",
      "Epoch 956/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3897 - acc: 0.8250 - val_loss: 0.4176 - val_acc: 0.8250\n",
      "Epoch 957/1000\n",
      "200/200 [==============================] - 0s 139us/step - loss: 0.3891 - acc: 0.8250 - val_loss: 0.4197 - val_acc: 0.8250\n",
      "Epoch 958/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3900 - acc: 0.8250 - val_loss: 0.4206 - val_acc: 0.8237\n",
      "Epoch 959/1000\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.3894 - acc: 0.8250 - val_loss: 0.4202 - val_acc: 0.8237\n",
      "Epoch 960/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3898 - acc: 0.8250 - val_loss: 0.4197 - val_acc: 0.8237\n",
      "Epoch 961/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3899 - acc: 0.8250 - val_loss: 0.4198 - val_acc: 0.8237\n",
      "Epoch 962/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3894 - acc: 0.8250 - val_loss: 0.4185 - val_acc: 0.8250\n",
      "Epoch 963/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3892 - acc: 0.8250 - val_loss: 0.4182 - val_acc: 0.8237\n",
      "Epoch 964/1000\n",
      "200/200 [==============================] - 0s 151us/step - loss: 0.3891 - acc: 0.8250 - val_loss: 0.4183 - val_acc: 0.8213\n",
      "Epoch 965/1000\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.3889 - acc: 0.8200 - val_loss: 0.4185 - val_acc: 0.8187\n",
      "Epoch 966/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.3903 - acc: 0.8200 - val_loss: 0.4203 - val_acc: 0.8187\n",
      "Epoch 967/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3902 - acc: 0.8200 - val_loss: 0.4194 - val_acc: 0.8187\n",
      "Epoch 968/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3895 - acc: 0.8300 - val_loss: 0.4209 - val_acc: 0.8213\n",
      "Epoch 969/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3889 - acc: 0.8250 - val_loss: 0.4215 - val_acc: 0.8225\n",
      "Epoch 970/1000\n",
      "200/200 [==============================] - 0s 157us/step - loss: 0.3889 - acc: 0.8250 - val_loss: 0.4195 - val_acc: 0.8250\n",
      "Epoch 971/1000\n",
      "200/200 [==============================] - 0s 152us/step - loss: 0.3904 - acc: 0.8200 - val_loss: 0.4174 - val_acc: 0.8213\n",
      "Epoch 972/1000\n",
      "200/200 [==============================] - 0s 141us/step - loss: 0.3887 - acc: 0.8200 - val_loss: 0.4184 - val_acc: 0.8225\n",
      "Epoch 973/1000\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.3887 - acc: 0.8200 - val_loss: 0.4215 - val_acc: 0.8200\n",
      "Epoch 974/1000\n",
      "200/200 [==============================] - 0s 159us/step - loss: 0.3897 - acc: 0.8200 - val_loss: 0.4206 - val_acc: 0.8200\n",
      "Epoch 975/1000\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.3917 - acc: 0.8150 - val_loss: 0.4160 - val_acc: 0.8213\n",
      "Epoch 976/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3910 - acc: 0.8150 - val_loss: 0.4171 - val_acc: 0.8213\n",
      "Epoch 977/1000\n",
      "200/200 [==============================] - 0s 149us/step - loss: 0.3904 - acc: 0.8150 - val_loss: 0.4166 - val_acc: 0.8237\n",
      "Epoch 978/1000\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.3893 - acc: 0.8150 - val_loss: 0.4172 - val_acc: 0.8187\n",
      "Epoch 979/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3891 - acc: 0.8150 - val_loss: 0.4183 - val_acc: 0.8213\n",
      "Epoch 980/1000\n",
      "200/200 [==============================] - 0s 134us/step - loss: 0.3885 - acc: 0.8150 - val_loss: 0.4197 - val_acc: 0.8225\n",
      "Epoch 981/1000\n",
      "200/200 [==============================] - 0s 165us/step - loss: 0.3891 - acc: 0.8150 - val_loss: 0.4190 - val_acc: 0.8213\n",
      "Epoch 982/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3888 - acc: 0.8150 - val_loss: 0.4192 - val_acc: 0.8213\n",
      "Epoch 983/1000\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.3886 - acc: 0.8150 - val_loss: 0.4198 - val_acc: 0.8200\n",
      "Epoch 984/1000\n",
      "200/200 [==============================] - 0s 142us/step - loss: 0.3893 - acc: 0.8150 - val_loss: 0.4211 - val_acc: 0.8225\n",
      "Epoch 985/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3889 - acc: 0.8200 - val_loss: 0.4184 - val_acc: 0.8213\n",
      "Epoch 986/1000\n",
      "200/200 [==============================] - 0s 143us/step - loss: 0.3911 - acc: 0.8150 - val_loss: 0.4176 - val_acc: 0.8225\n",
      "Epoch 987/1000\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.3896 - acc: 0.8200 - val_loss: 0.4209 - val_acc: 0.8225\n",
      "Epoch 988/1000\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.3892 - acc: 0.8200 - val_loss: 0.4227 - val_acc: 0.8237\n",
      "Epoch 989/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3885 - acc: 0.8250 - val_loss: 0.4229 - val_acc: 0.8213\n",
      "Epoch 990/1000\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3894 - acc: 0.8250 - val_loss: 0.4207 - val_acc: 0.8250\n",
      "Epoch 991/1000\n",
      "200/200 [==============================] - 0s 132us/step - loss: 0.3889 - acc: 0.8150 - val_loss: 0.4201 - val_acc: 0.8250\n",
      "Epoch 992/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3900 - acc: 0.8150 - val_loss: 0.4186 - val_acc: 0.8237\n",
      "Epoch 993/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3889 - acc: 0.8150 - val_loss: 0.4185 - val_acc: 0.8213\n",
      "Epoch 994/1000\n",
      "200/200 [==============================] - 0s 131us/step - loss: 0.3887 - acc: 0.8150 - val_loss: 0.4189 - val_acc: 0.8200\n",
      "Epoch 995/1000\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.3886 - acc: 0.8200 - val_loss: 0.4200 - val_acc: 0.8225\n",
      "Epoch 996/1000\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.3889 - acc: 0.8200 - val_loss: 0.4216 - val_acc: 0.8237\n",
      "Epoch 997/1000\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.3888 - acc: 0.8250 - val_loss: 0.4205 - val_acc: 0.8225\n",
      "Epoch 998/1000\n",
      "200/200 [==============================] - 0s 137us/step - loss: 0.3877 - acc: 0.8200 - val_loss: 0.4187 - val_acc: 0.8225\n",
      "Epoch 999/1000\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3889 - acc: 0.8150 - val_loss: 0.4180 - val_acc: 0.8213\n",
      "Epoch 1000/1000\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.3896 - acc: 0.8150 - val_loss: 0.4201 - val_acc: 0.8187\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=1000, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.825, Test: 0.819\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaUikIa7UkpFIA13pZSKQBruSikVgf4fNvjqex1qBoUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1311af6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot learning curves of model accuracy\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind-dog]",
   "language": "python",
   "name": "conda-env-aind-dog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
